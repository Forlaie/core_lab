[
    {
        "series": "ACE '25",
        "location": "",
        "keywords": "Testing, CS2, Programming, Gamification, Computing Education",
        "numpages": "10",
        "pages": "46\u201355",
        "booktitle": "Proceedings of the 27th Australasian Computing Education Conference",
        "abstract": "Students struggle to understand why rigorous testing is necessary, often testing with a small number of examples and testing interactively instead of through a framework. Our goal is to encourage students to meaningfully engage in the testing process. We do so by developing a system, Codetierlist, that gamifies the process of testing on a programming assignment in a first-year programming course (CS2). Student tests for a programming assignment are run against both the instructor solution and other student solutions, and students receive feedback, in the form of a tier-based ranking, on how well their solution compares to fellow students within the shared student test suite. We compared the tests and assignment solutions students produced with and without Codetierlist. We also gathered student and instructor feedback on the experience of using the tool and measured student motivation and self-efficacy regarding testing. Students wrote more functionally correct code with Codetierlist, and they wrote significantly more and more precise tests with Codetierlist, even identifying previously unknown bugs in the instructor solution. We did not detect any changes to student self-efficacy, but students reported feeling more positive about testing and more motivated to test with Codetierlist. However, we also detected negative effects from the gamification method selected, as some students whose code was placed in a lower tier felt discouraged and less able to succeed. Additionally, we found that improvements to motivation and efficacy may vary based on a student\u2019s prior experience. We provide the community with a tool, Codetierlist, for motivating students to engage more actively with testing in an assignment setting, and identify positive aspects of providing students with a target to test against. However, we reiterate the need for caution when introducing gamified elements that might be viewed as encouraging competition, as students who receive negative feedback from a comparison may feel unable to improve their situation.",
        "doi": "10.1145/3716640.3716646",
        "url": "https://doi.org/10.1145/3716640.3716646",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400714252",
        "year": "2025",
        "title": "Codetierlist: Competitive Gamification's Impact on Self-Efficacy, Motivation, and Performance in Computing Education",
        "author": [
            "Yousef Bulbulia",
            "Ido Ben Haim",
            "Jackson Lee",
            "Brian Zhang",
            "Daksh Malhotra",
            "Andrew Petersen",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "02Bulbulia25"
    },
    {
        "series": "ITiCSE 2024",
        "location": "Milan, Italy",
        "keywords": "curriculum, data engineering, data systems, database, education, industry, knowledge gap, skill set",
        "numpages": "29",
        "pages": "95\u2013123",
        "booktitle": "2024 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "Data systems have been an important part of computing curricula for decades, and an integral part of data-focused industry roles such as software developers, data engineers, and data scientists. However, the field of data systems encompasses a large number of topics ranging from data manipulation and database distribution to creating data pipelines and data analytics solutions. Due to the slow nature of curriculum development, it remains unclear (i) which data systems topics are recommended across diverse higher education curriculum guidelines, (ii) which topics are taught in higher education data systems courses, and (iii) which data systems topics are actually valued in data-focused industry roles. In this study, we analyzed computing curriculum guidelines, course contents, and industry needs regarding data systems to uncover discrepancies between them. Our results show, for example, that topics such as data visualization, data warehousing, and semi-structured data models are valued in industry, yet seldom taught in courses. This work allows professionals to further align curriculum guidelines, higher education, and data systems industry to better prepare students for their working life by focusing on relevant skills in data systems education.",
        "doi": "10.1145/3689187.3709609",
        "url": "https://doi.org/10.1145/3689187.3709609",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400712081",
        "year": "2025",
        "title": "Data Systems Education: Curriculum Recommendations, Course Syllabi, and Industry Needs",
        "author": [
            "Daphne Miedema",
            "Toni Taipalus",
            "Vangel V. Ajanovski",
            "Abdussalam Alawini",
            "Martin Goodfellow",
            "Michael Liut",
            "Svetlana Peltsverger",
            "Tiffany Young"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "01Miedema25"
    },
    {
        "series": "ITiCSE 2025",
        "location": "Nijmegen, Netherlands",
        "keywords": "mastery learning, pedagogy, student-paced learning",
        "numpages": "7",
        "pages": "639\u2013645",
        "booktitle": "Proceedings of the 30th ACM Conference on Innovation and Technology in Computer Science Education V. 1",
        "abstract": "Mastery learning was first defined in the late 1960s, but despite the promise of a student-focused methodology to establish firm foundations for later studies, it has not been widely adopted. In this paper, we consider why. We consider the evidence for mastery learning, and explore the organisational, structural, staffing, and pedagogical needs and challenges. We find, immediately, that there are competing implementations for mastery learning in computing education. We propose a way of representing pedagogical theories that use aspects of mastery learning in a way that allows a clear separation of techniques that appear similar but are not identical, to ensure the most appropriate implementation for a given area of application. These techniques still share similar challenges for adoption. We build towards possible solutions by considering recent developments in generative AI---and how these technologies could potentially provide automated assistants as a supporting component of mastery learning, in order to fully realise Bloom's vision.",
        "doi": "10.1145/3724363.3729104",
        "url": "https://doi.org/10.1145/3724363.3729104",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400715679",
        "year": "2025",
        "title": "Show Me the Mastery Learning! Obstacles to Adoption and Opportunities for New Solutions",
        "author": [
            "Claudio Alvarez",
            "Nickolas Falkner",
            "Paivi Kinnunen",
            "Jaromir Savelka",
            "Lisa Zhang"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Zhang25"
    },
    {
        "series": "ITiCSE 2024",
        "location": "Milan, Italy",
        "keywords": "artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models",
        "numpages": "34",
        "pages": "34\u201367",
        "booktitle": "2024 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively",
        "doi": "10.1145/3689187.3709607",
        "url": "https://doi.org/10.1145/3689187.3709607",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400712081",
        "year": "2025",
        "title": "AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies",
        "author": [
            "Tony Clear",
            "Asa Cajander",
            "Alison Clear",
            "Roger McDermott",
            "Mats Daniels",
            "Monica Divitini",
            "Matthew Forshaw",
            "Niklas Humble",
            "Maria Kasinidou",
            "Styliani Kleanthous",
            "Can Kultur",
            "Ghazaleh Parvini",
            "Mohammad Polash",
            "Tingting Zhu"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "01Zhu25"
    },
    {
        "series": "SIGCSETS 2025",
        "location": "Pittsburgh, PA, USA",
        "keywords": "computing education, databases, generative artificial intelligence, large language models, student behavior, student performance",
        "numpages": "7",
        "pages": "959\u2013965",
        "booktitle": "Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1",
        "abstract": "Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.",
        "doi": "10.1145/3641554.3701785",
        "url": "https://doi.org/10.1145/3641554.3701785",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400705311",
        "year": "2025",
        "title": "Understanding the Impact of Using Generative AI Tools in a Database Course",
        "author": [
            "Valeria Ramirez Osorio",
            "Angela Zavaleta Bernuy",
            "Bogdan Simion",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Zavaleta25"
    },
    {
        "series": "ITiCSE 2024",
        "location": "Milan, Italy",
        "keywords": "DEIA, E&I, EDI, accessibility, diversity, equity, inclusion, industry expectations, non-technical skills, professional dispositions, professionalism",
        "numpages": "51",
        "pages": "124\u2013174",
        "booktitle": "2024 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "Computing graduates are frequently reported by members of industry to lack in professional dispositions and/or non-technical skills (often referred to as \"soft skills\"). In this work, we conduct a gap analysis of the alignment between academic preparation and industry expectations through a three-pronged study. First, a literature review explored the academic perspective of how fostering professional dispositions and non-technical skills occurs in tertiary computing education. Second, a literature review identifying industry's expectations of those dispositions and skills for entry-level computing professionals. Finally, a mixed-methods approach, combining a survey and structured interviews of computing industry professionals to identify their opinions on the relative importance of those skills and dispositions. In each of these prongs, we additionally consider whether and how Diversity, Equity, Inclusion, and Accessibility (DEIA) may have been approached and/or incorporated.Our work uncovers a number of gaps. Several skills and dispositions, such as leadership, ethics, and inventiveness, are over-represented in the academic literature compared to industry's expectations, while others such as lifelong learning and professionalism are under-emphasised. Furthermore, some terms such as 'ethics' and 'professionalism' are defined differently by various stakeholder groups, leading to a gap between academic training and industry expectations. Finally, several skills and dispositions, such as collaboration, teamwork, communication, and leadership show evidence of exposure in academia, but require more scaffolded instruction to meet industry expectations. We also found a dearth of coverage in the literature and a lack of focus in industry for DEIA considerations.",
        "doi": "10.1145/3689187.3709610",
        "url": "https://doi.org/10.1145/3689187.3709610",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400712081",
        "year": "2025",
        "title": "An International Examination of Non-Technical Skills and Professional Dispositions in Computing -- Identifying the Present Day Academia-Industry Gap",
        "author": [
            "Rita Garcia",
            "Andrew Csizmadia",
            "Janice L. Pearce",
            "Bedour Alshaigy",
            "Olga Glebova",
            "Brian Harrington",
            "Konstantinos Liaskos",
            "Stephanie J. Lunn",
            "Bonnie Mackellar",
            "Usman Nasir",
            "Raymond Pettit",
            "Sandra Schulz",
            "Craig Stewart",
            "Angela Zavaleta Bernuy"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "01Zavaleta25"
    },
    {
        "series": "Koli Calling '24",
        "location": "",
        "keywords": "visualization, multiple representations theory, code tracing, introductory programming",
        "numpages": "2",
        "articleno": "25",
        "booktitle": "Proceedings of the 24th Koli Calling International Conference on Computing Education Research",
        "abstract": "This pilot study explores how visualization strategies, grounded in multiple representations theory, impact novice students\u2019 engagement, and cognitive load during program tracing tasks. Students were were shown a visualization of the three-variable swap problem at the start of an introductory programming course (CS1) at a large public North American research-intensive university. We compared three conditions: interactive multiple representations, Python Tutor (a single-representation tool), and text-only methods. Preliminary results indicate that interactive multiple representations increase engagement for students with prior programming experience, while no significant differences were observed for students without prior experience. These findings suggest that while multiple representations may boost engagement, identifying how to effectively support students of all experience levels and reduce cognitive load requires further study.",
        "doi": "10.1145/3699538.3699587",
        "url": "https://doi.org/10.1145/3699538.3699587",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400710384",
        "year": "2024",
        "title": "Exploring the Impact of Multiple Representations in Introductory Programming: A Pilot Study",
        "author": [
            "Naaz Sibia",
            "Valeria Ramirez Osorio",
            "Angela Zavaleta Bernuy",
            "Efthimia Aivaloglou",
            "Rutwa Engineer",
            "Andrew Petersen",
            "Michael Liut",
            "Carolina Nobre"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11Sibia24"
    },
    {
        "keywords": "artificial intelligence in education, collaborative learning with ai, human-ai collaboration, large language models, transparency, tutoring systems",
        "numpages": "30",
        "articleno": "499",
        "month": "November",
        "journal": "Proc. ACM Hum.-Comput. Interact.",
        "abstract": "Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role that teachers can play in shaping LLM-supported learning environments.",
        "doi": "10.1145/3687038",
        "url": "https://doi.org/10.1145/3687038",
        "number": "CSCW2",
        "volume": "8",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "issue_date": "November 2024",
        "year": "2024",
        "title": "Guiding Students in Using LLMs in Supported Learning Environments: Effects on Interaction Dynamics, Learner Performance, Confidence, and Trust",
        "author": [
            "Harsh Kumar",
            "Ilya Musabirov",
            "Mohi Reza",
            "Jiakai Shi",
            "Xinyuan Wang",
            "Joseph Jay Williams",
            "Anastasia Kuzminykh",
            "Michael Liut"
        ],
        "ENTRYTYPE": "article",
        "ID": "11Kumar24"
    },
    {
        "pages": "23-32",
        "month": "Oct.",
        "year": "2024",
        "author": [
            "Jessica Y. Bo",
            "Harsh Kumar",
            "Michael Liut",
            "Ashton Anderson"
        ],
        "journal": "Proceedings of the AAAI Conference on Human Computation and Crowdsourcing",
        "number": "1",
        "abstract": "Large Language Models (LLMs) are increasingly being used in educational settings to assist students with assignments and learning new concepts. For LLMs to be effective learning aids, students must develop an appropriate level of trust and reliance on these tools. Misaligned trust and reliance can lead to suboptimal learning outcomes and reduced LLM engagement. Despite their growing presence, there is a limited understanding of achieving optimal transparency and reliance calibration in the educational use of LLMs. In a 3x2 between-subjects experiment conducted in a university classroom setting, we tested the effect of two transparency disclosures (System Prompt and Goal Summary) and an in-conversation Reliability Disclaimer on a GPT-4-based chatbot tutor provided to students for an assignment. Our findings suggest that disclaimer messages included in the responses may effectively mitigate learners\u2019 overreliance on the LLM Tutor in the presence of incorrect advice. Disclosing System Prompt seemed to calibrate students\u2019 confidence in their answers and reduce the occurrence of copy-pasting the exact assignment question to the LLM tutor. Student feedback indicated that they would like transparency framed in terms of performance-based metrics. Our work provides empirical insights on the design of transparency and reliability mechanisms for using LLMs in classrooms.",
        "doi": "10.1609/hcomp.v12i1.31597",
        "url": "https://ojs.aaai.org/index.php/HCOMP/article/view/31597",
        "volume": "12",
        "title": "Disclosures &amp; Disclaimers: Investigating the Impact of Transparency Disclosures and Reliability Disclaimers on Learner-LLM Interactions",
        "ENTRYTYPE": "article",
        "ID": "10Bo24"
    },
    {
        "series": "L@S '24",
        "location": "Atlanta, GA, USA",
        "keywords": "field experiments, human-ai collaboration, large language models, learning engineering, self-reflection",
        "numpages": "12",
        "pages": "86\u201397",
        "booktitle": "Proceedings of the Eleventh ACM Conference on Learning @ Scale",
        "abstract": "Self-reflection on learning experiences constitutes a fundamental cognitive process, essential for consolidating knowledge and enhancing learning efficacy. However, traditional methods to facilitate reflection often face challenges in personalization, immediacy of feedback, engagement, and scalability. Integration of Large Language Models (LLMs) into the reflection process could mitigate these limitations. In this paper, we conducted two randomized field experiments in undergraduate computer science courses to investigate the potential of LLMs to help students engage in post-lesson reflection. In the first experiment (N=145), students completed a take-home assignment with the support of an LLM assistant; half of these students were then provided access to an LLM designed to facilitate self-reflection. The results indicated that the students assigned to LLM-guided reflection reported somewhat increased self-confidence compared to peers in a no-reflection control and a non-significant trend towards higher scores on a later assessment. Thematic analysis of students' interactions with the LLM showed that the LLM often affirmed the student's understanding, expanded on the student's reflection, and prompted additional reflection; these behaviors suggest ways LLM-interaction might facilitate reflection. In the second experiment (N=112), we evaluated the impact of LLM-guided self-reflection against other scalable reflection methods, such as questionnaire-based activities and review of key lecture slides, after assignment. Our findings suggest that the students in the questionnaire and LLM-based reflection groups performed equally well and better than those who were only exposed to lecture slides, according to their scores on a proctored exam two weeks later on the same subject matter. These results underscore the utility of LLM-guided reflection and questionnaire-based activities in improving learning outcomes. Our work highlights that focusing solely on the accuracy of LLMs can overlook their potential to enhance metacognitive skills through practices such as self-reflection. We discuss the implications of our research for the learning-at-scale community, highlighting the potential of LLMs to enhance learning experiences through personalized, engaging, and scalable reflection practices.",
        "doi": "10.1145/3657604.3662042",
        "url": "https://doi.org/10.1145/3657604.3662042",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400706332",
        "year": "2024",
        "title": "Supporting Self-Reflection at Scale with Large Language Models: Insights from Randomized Field Experiments in Classrooms",
        "author": [
            "Harsh Kumar",
            "Ruiwei Xiao",
            "Benjamin Lawson",
            "Ilya Musabirov",
            "Jiakai Shi",
            "Xinyuan Wang",
            "Huayin Luo",
            "Joseph Jay Williams",
            "Anna N. Rafferty",
            "John Stamper",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07Kumar24"
    },
    {
        "doi": "10.1109/COMPSAC61105.2024.00027",
        "keywords": "Measurement;Accuracy;Plagiarism;Large language models;Education;Detectors;Chatbots;Large Language Models;ChatGPT;GPT;AI Detectors;Plagiarism;Academic Integrity",
        "url": "https://doi.org/10.1109/COMPSAC61105.2024.00027",
        "pages": "121-126",
        "number": "",
        "volume": "",
        "year": "2024",
        "title": "Detecting LLM-Generated Text in Computing Education: Comparative Study for ChatGPT Cases",
        "booktitle": "2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)",
        "author": [
            "Michael Sheinman Orenstrakh",
            "Oscar Karnalim",
            "Carlos An\u00edbal Su\u00e1rez",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Sheinman24"
    },
    {
        "series": "WCCCE '24",
        "location": "<conf-loc>, <city>Kelowna</city>, <state>BC</state>, <country>Canada</country>, </conf-loc>",
        "keywords": "Thompson sampling, adaptive experimentation, continuous improvement, multiarmed bandit",
        "numpages": "7",
        "articleno": "4",
        "booktitle": "The 26th Western Canadian Conference on Computing Education",
        "abstract": "Randomized A/B comparisons of alternative pedagogical strategies or other course improvements could provide useful empirical evidence for instructor decision-making. However, traditional experiments do not provide a straightforward pathway to rapidly utilize data, increasing the chances that students in an experiment experience the best conditions. Drawing inspiration from the use of machine learning and experimentation in product development at leading technology companies, we explore how adaptive experimentation might aid continuous course improvement. In adaptive experiments, data is analyzed and utilized as different conditions are deployed to students. This can be achieved using machine learning algorithms to identify which actions are more beneficial in improving students\u2019 learning experiences and outcomes. These algorithms can then dynamically deploy the most effective conditions in subsequent interactions with students, resulting in better support for students\u2019 needs. We illustrate this approach with a case study that provides a side-by-side comparison of traditional and adaptive experiments on adding self-explanation prompts in online homework problems in a CS1 course. This work paves the way for exploring the importance of adaptive experiments in bridging research and practice to achieve continuous improvement in educational settings.",
        "doi": "10.1145/3660650.3660659",
        "url": "https://doi.org/10.1145/3660650.3660659",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400709975",
        "year": "2024",
        "title": "Opportunities for Adaptive Experiments to Enable Continuous Improvement in Computer Science Education",
        "author": [
            "Ilya Musabirov",
            "Angela Zavaleta Bernuy",
            "Pan Chen",
            "Michael Liut",
            "Joseph Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "05Musabirov24"
    },
    {
        "series": "WCCCE '24",
        "location": "<conf-loc>, <city>Kelowna</city>, <state>BC</state>, <country>Canada</country>, </conf-loc>",
        "keywords": "CS1, student experience, transition, upper-year",
        "numpages": "7",
        "articleno": "5",
        "booktitle": "The 26th Western Canadian Conference on Computing Education",
        "abstract": "While the challenges experienced by first-year computing students have been well studied, little work has explored the transitions in disciplinary participation and challenges experienced by upper-years. This study explores how students\u2019 needs and challenges evolve through a computing degree. We collected the experiences of first to final-year undergraduate computing students through surveys and interviews. We organized these experiences into themes that we compare against previous literature and illustrate with quotes. Upper-year students perceive changes in (a) levels of support and (b) the kinds of challenges they experience as they progress through the program. Second-year students feel pressured by the increasing difficulty of courses. This pressure increases through the third year as students begin to perceive a need to find employment. The experiences of our students suggest the need to better support the middle years of academic programs. Students in the first year are well-supported in their university transition, but students in the middle are often left to find their way as they develop a deeper understanding of their desired place in the field.",
        "doi": "10.1145/3660650.3660661",
        "url": "https://doi.org/10.1145/3660650.3660661",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400709975",
        "year": "2024",
        "title": "Student Transitions Through an Entire Computing Program",
        "author": [
            "Angela Zavaleta Bernuy",
            "Andrew Chung",
            "Alana Hodge",
            "Ayesha Tayyiba",
            "Michael Liut",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "05Zavaleta24"
    },
    {
        "series": "CHI '24",
        "location": "<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>",
        "keywords": "datasets, gaze detection, neural networks, text tagging",
        "numpages": "18",
        "articleno": "1042",
        "booktitle": "Proceedings of the CHI Conference on Human Factors in Computing Systems",
        "abstract": "Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers' flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p < 0.001), enhances user perceptions of the revision process (d = 2.41, p < 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.",
        "doi": "10.1145/3613904.3641899",
        "url": "https://doi.org/10.1145/3613904.3641899",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400703300",
        "year": "2024",
        "title": "ABScribe: Rapid Exploration \\& Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models",
        "author": [
            "Mohi Reza",
            "Nathan M Laundry",
            "Ilya Musabirov",
            "Peter Dushniku",
            "Zhi Yuan \"Michael\" Yu",
            "Kashish Mittal",
            "Tovi Grossman",
            "Michael Liut",
            "Anastasia Kuzminykh",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "05Reza24"
    },
    {
        "series": "CHI '24",
        "location": "<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>",
        "keywords": "ChatGPT, Education, GPT-4, Large Language Models, Personalized Reflections, Procrastination",
        "numpages": "18",
        "articleno": "15",
        "booktitle": "Proceedings of the CHI Conference on Human Factors in Computing Systems",
        "abstract": "Traditional interventions for academic procrastination often fail to capture the nuanced, individual-specific factors that underlie them. Large language models (LLMs) hold immense potential for addressing this gap by permitting open-ended inputs, including the ability to customize interventions to individuals' unique needs. However, user expectations and potential limitations of LLMs in this context remain underexplored. To address this, we conducted interviews and focus group discussions with 15 university students and 6 experts, during which a technology probe for generating personalized advice for managing procrastination was presented. Our results highlight the necessity for LLMs to provide structured, deadline-oriented steps and enhanced user support mechanisms. Additionally, our results surface the need for an adaptive approach to questioning based on factors like busyness. These findings offer crucial design implications for the development of LLM-based tools for managing procrastination while cautioning the use of LLMs for therapeutic guidance.",
        "doi": "10.1145/3613904.3642081",
        "url": "https://doi.org/10.1145/3613904.3642081",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400703300",
        "year": "2024",
        "title": "Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination",
        "author": [
            "Ananya Bhattacharjee",
            "Yuchen Zeng",
            "Sarah Yi Xu",
            "Dana Kulzhabayeva",
            "Minyi Ma",
            "Rachel Kornfield",
            "Syed Ishtiaque Ahmed",
            "Alex Mariakakis",
            "Mary P Czerwinski",
            "Anastasia Kuzminykh",
            "Michael Liut",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "05Liut24"
    },
    {
        "series": "SIGCSE 2024",
        "location": "Portland, OR, USA",
        "keywords": "computing education, cs for all, equity, guidelines, high-quality, post-secondary, primary, research, secondary",
        "numpages": "2",
        "pages": "1871\u20131872",
        "booktitle": "Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2",
        "abstract": "While there are multiple standards bodies that define characteristics of high-quality, there are limited guidelines on conducting equity-enabling research, particularly in the context of high quality and in computing education. As part of an ACM ITiCSE Working Group in 2023, we engaged in a concept analysis and structured literature review to identify high-impact practices for conducting both high-quality and equity-enabling education research. As a result of this work, we produced a set of guidelines across each major phase of research that integrates characteristics of high-quality education research with those that are necessary for producing research that is designed to honor and meet the needs of various subgroups of learners. Special emphasis is given to the role that the researcher plays in shaping the research based upon how the researcher's lived experiences, perspectives, and training influences their work. During this special session, we will review each set of guidelines and engage attendees in reflection and discussion of them and how they can use the guidelines to enhance their education research.",
        "doi": "10.1145/3626253.3633402",
        "url": "https://doi.org/10.1145/3626253.3633402",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400704246",
        "year": "2024",
        "title": "Unlocking Excellence in Educational Research: Guidelines for High-Quality Research that Promotes Learning for All",
        "author": [
            "Monica M. McGill",
            "Sarah Heckman",
            "Michael Liut",
            "Ismaila Temitayo Sanusi",
            "Claudia Szabo"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03McGill24"
    },
    {
        "series": "SIGCSE 2024",
        "location": "Portland, OR, USA",
        "keywords": "help-seeking behavior, intelligent tutoring systems, on-demand hints, self-regulated learning",
        "numpages": "2",
        "pages": "1578\u20131579",
        "booktitle": "Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2",
        "abstract": "Asking for help (help-seeking) is a recognized and effective problem-solving strategy. This study investigates students' interaction with on-demand hints (automated hints requested by students) and assesses their impact on learning progress. We conducted an A/B experiment in a third-year computer science database course, offering hints for selected SQL problems with different hint designs. We collected data on students' code submissions, grades, and hint requests, and we administered a survey to gather feedback and gauge student perception of the hints. Many students accessed hints immediately without attempting the problem first, often requesting multiple hints in quick succession. While students perceived the hints to be valuable, we did not detect an impact on student problem-solving. These insights could inform future studies on the possible impact of students' attitudes toward hints, and how different types of hints might impact uptake and perception of hints.",
        "doi": "10.1145/3626253.3635563",
        "url": "https://doi.org/10.1145/3626253.3635563",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400704246",
        "year": "2024",
        "title": "Do Hints Enhance Learning in Programming Exercises? Exploring Students' Problem-Solving and Interactions",
        "author": [
            "Giang Bui",
            "Nicholas Susanto",
            "Naaz Sibia",
            "Angela Zavaleta Bernuy",
            "Michael Liut",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Bui24"
    },
    {
        "series": "SIGCSE 2024",
        "location": "<conf-loc>, <city>Portland</city>, <state>OR</state>, <country>USA</country>, </conf-loc>",
        "keywords": "academic dishonesty, academic integrity, assessment, cheating, computer science students, computing students, education",
        "numpages": "7",
        "pages": "757\u2013763",
        "booktitle": "Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1",
        "abstract": "In contrast with studies that have identified why students commit academic offences, many educators are familiar with the excuse that an accused student did not know the behavior counted as dishonest. Given the variations in policy and the ways collaboration and code sharing occur in professional and hobbyist spaces, this might be plausible. Mismatches between students' conceptions of academic honesty and course policy can have major consequences, from being kicked out of programs to being too nervous to study with peers. In this work, we investigate what students understand about academic integrity in computer science courses and if there are differences based on university, country, demographic, or online versus in-person courses. We present a study that surveys undergraduate computer science students (N = 1,011) at three universities (Australia, Canada, and the United States of America). The results show that all three institutions take academic integrity seriously, and their students are aware of its importance, but confusion on what is covered under the policies is common. Interestingly, the results also show that course instructors play a huge role as to what students perceive to be a violation of the academic integrity policy at their institution. By understanding student's perspectives on academic integrity, educators can better develop policies and practices that reduce inadvertent and mistaken violations of academic integrity policies.",
        "doi": "10.1145/3626252.3630753",
        "url": "https://doi.org/10.1145/3626252.3630753",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400704239",
        "year": "2024",
        "title": "\"I Didn't Know\": Examining Student Understanding of Academic Dishonesty in Computer Science",
        "author": [
            "Michael Liut",
            "Anna Ly",
            "Jessica Jia-Ni Xu",
            "Justice Banson",
            "Paul Vrbik",
            "Caroline D. Hardin"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Liut24"
    },
    {
        "series": "Koli Calling '23",
        "location": "<conf-loc>, <city>Koli</city>, <country>Finland</country>, </conf-loc>",
        "keywords": "Data Systems Education, Databases, Misconceptions, SQL",
        "numpages": "12",
        "articleno": "10",
        "booktitle": "Proceedings of the 23rd Koli Calling International Conference on Computing Education Research",
        "abstract": "In recent years, database education has been receiving more attention, with research in various directions such as the development of tools for education, the analysis of students\u2019 homework, and the exploration of misconceptions. Misconceptions are mistakes in student reasoning that lead to errors during problem-solving. Recent work has documented misconceptions and errors in SQL. In this study we test the prevalence of several of these misconceptions through a multiple-choice questionnaire, to see if they hold on a larger, more diverse, student population. We found that all misconceptions are held to some extent, with prevalence scores ranging from one to fifty-two percent of the student population. Additionally, we have uncovered previously unidentified areas of struggle, allowing us to identify new misconceptions.",
        "doi": "10.1145/3631802.3631821",
        "url": "https://doi.org/10.1145/3631802.3631821",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400716539",
        "year": "2024",
        "title": "\u201cThere is no ambiguity on what to return\u201d: Investigating the Prevalence of SQL Misconceptions",
        "author": [
            "Daphne Miedema",
            "Michael Liut",
            "George H. L. Fletcher",
            "Efthimia Aivaloglou"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "01Miedema23"
    },
    {
        "annote": "Keywords: chatgpt, computing education, llms, machine learning, mastery learning",
        "doi": "10.4230/DagRep.14.6.245",
        "urn": "urn:nbn:de:0030-drops-227277",
        "url": "https://drops.dagstuhl.de/entities/document/10.4230/DagRep.14.6.245",
        "address": "Dagstuhl, Germany",
        "publisher": "Schloss Dagstuhl -- Leibniz-Zentrum f{\\\"u}r Informatik",
        "editor": "Falkner, Nick and Leinonen, Juho and Parker, Miranda C. and Petersen, Andrew and Szabo, Claudia",
        "number": "6",
        "volume": "14",
        "year": "2024",
        "issn": "2192-5283",
        "journal": "Dagstuhl Reports",
        "pages": "245--262",
        "title": "{A Game of Shadows: Effective Mastery Learning in the Age of Ubiquitous AI (Dagstuhl Seminar 24272)}",
        "author": [
            "Nick Falkner",
            "Juho Leinonen",
            "Miranda C. Parker",
            "Andrew Petersen",
            "Claudia Szabo"
        ],
        "ENTRYTYPE": "article",
        "ID": "12Falkner24"
    },
    {
        "series": "SIGCSE Virtual 2024",
        "location": "Virtual Event, NC, USA",
        "keywords": "hash tables, hashset, java, notional machine",
        "numpages": "7",
        "pages": "109\u2013115",
        "booktitle": "Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1",
        "abstract": "Background: Notional machines appear to be an essential aspect of computing education, but there are few papers that identify strengths and weaknesses of particular notional machines. Purpose: This article fills a gap in the notional machine literature by using a randomized controlled trial to compare the effectiveness of different notional machine representations. Methods: Our study used notional machines for two hash table algorithms: chaining and open addressing. Students were randomly assigned a video sequence using either 2D or 3D representations. Findings: We found minimal effect of 2D vs 3D representational form on students' learning and perceptions of helpfulness. Implications: Our paper provides an example of how educational research can inform the design and evaluation of notional machines.",
        "doi": "10.1145/3649165.3690118",
        "url": "https://doi.org/10.1145/3649165.3690118",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400705984",
        "year": "2024",
        "title": "Hash Table Notional Machines: A Comparison of 2D and 3D Representations",
        "author": [
            "Colleen M. Lewis",
            "Craig S. Miller",
            "Johan Jeuring",
            "Janice L. Pearce",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12Lewis24"
    },
    {
        "series": "Koli Calling '23",
        "location": "<conf-loc>, <city>Koli</city>, <country>Finland</country>, </conf-loc>",
        "keywords": "AI, Common Errors, Data science, Machine learning, Misconceptions",
        "numpages": "12",
        "articleno": "11",
        "booktitle": "Proceedings of the 23rd Koli Calling International Conference on Computing Education Research",
        "abstract": "While machine learning (ML) has proved impactful in many disciplines, design decisions involved in building ML models are difficult for novices to make, and mistakes can cause harm. Prior work by Skripchuk et&nbsp;al. [35] identified common errors made by ML students via qualitative analysis of open-ended ML assessments, but their sample was limited to a single institution, course, and assessment setting. Our work is an extended, conceptual replication of this work to understand the common errors made by machine learning students. We use a mixed-method approach to analyze errors in 30 final project reports in an undergraduate machine learning course. The final reports describe the model-building process for a classification task, where students build models on a complex data set with numerical, categorical, ordinal and text features. Our choice to analyze project reports (rather than code) allows us to uncover design errors via how students justify their methodology. Our project task is to achieve the best test accuracy on an unseen test set; thus, as a way to validate these common errors, we identify the association between these errors and the model\u2019s test accuracy performance. Common errors we find include those consistent with Skripchuk et&nbsp;al. [35], for example issues with data processing, hyperparameter tuning, and model selection. In addition, our focus on design error exposes other common errors, for example where students use certain kinds of features (e.g., bag of words representations) only with particular models (e.g., Naive Bayes). We call these latter types of errors model misconceptions, and such errors are associated with lower test accuracy. Some of these errors are also present in work by practitioners. Others reflect a difficulty by students to make correct connections between ML concepts and achieve the relational level of the SOLO taxonomy. We identify areas of opportunity to improve machine learning pedagogy, particularly related to data processing, data leakage, hyperparameters, nonsensical outputs, and disentangling data decisions from model decisions.",
        "doi": "10.1145/3631802.3631808",
        "url": "https://doi.org/10.1145/3631802.3631808",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400716539",
        "year": "2024",
        "title": "Common Errors in Machine Learning Projects: A Second Look",
        "author": [
            "Renato Magela Zimmermann",
            "Sonya Allin",
            "Lisa Zhang"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "01Zimmermann23"
    },
    {
        "series": "ITiCSE 2024",
        "location": "Milan, Italy",
        "keywords": "computer science education, curriculum, technical writing skills, wac, wid, written communication, wtl",
        "numpages": "7",
        "pages": "332\u2013338",
        "booktitle": "Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1",
        "abstract": "Faculty and industry practitioners recognize written communication to be important in computer science, but it can be challenging to convince students of the same. As student perceptions are molded early in a program of study, we focus on early-year CS students to understand their perceptions towards the importance of writing in CS, with the goal of framing discipline-specific writing pedagogy. We qualitatively analyze responses from first and second-year CS students in a survey about the role of writing in their field. The responses reveal that a majority view writing as an indispensable skill. Specifically, students recognize it as a fundamental skill, applicable across diverse contexts, and uniquely relevant in CS compared to other fields. We identified 4 perceptions that they hold which are helpful to their development as writers: that writing is a useful fundamental skill, which is useful for achieving various goals in a variety of contexts, and that writing in CS is different than in other fields. However, 20\\% of responses include reasons why writing is not important in CS, and we identify 4 perceptions harmful to students' development as writers: that writing skills can be avoided, are defined narrowly, do not need to be developed beyond a baseline, and come at the cost of computing skills. We believe that there is an opportunity to align discipline-specific writing instruction with these useful and harmful perceptions.",
        "doi": "10.1145/3649217.3653576",
        "url": "https://doi.org/10.1145/3649217.3653576",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400706004",
        "year": "2024",
        "title": "Early Computer Science Students' Perspectives Towards The Importance Of Writing",
        "author": [
            "Rutwa Engineer",
            "Naaz Sibia",
            "Michael Kaler",
            "Bogdan Simion",
            "Lisa Zhang"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07Engineer24"
    },
    {
        "series": "Koli Calling '23",
        "location": "<conf-loc>, <city>Koli</city>, <country>Finland</country>, </conf-loc>",
        "keywords": "email engagement, email open rates, instructor communication",
        "numpages": "12",
        "articleno": "13",
        "booktitle": "Proceedings of the 23rd Koli Calling International Conference on Computing Education Research",
        "abstract": "Email is an important mode of communication because it scales to the largest computing courses and is institutionally supported. Furthermore, regular email communication from instructors has been shown to help set student expectations and encourage participation. As a result, effective email can contribute to emotional engagement, which has been linked to improvements in performance and retention, the latter being a persistent problem in computer science. However, we lack a clear picture of how computing students interact with emails and whether their use aligns with instructors\u2019 expectations. This paper addresses this gap by presenting data on how often CS1 students open instructor emails. We present email engagement data throughout the term for a particular type of email that prompts students to plan to start their homework. Contrary to instructors\u2019 expectations, the rate at which students open emails of this kind does not change significantly over the term. Many students who engage with the emails do so consistently, even after repeated emails throughout the term. The patterns we found illustrate the value of collecting this type of data and informing instructors and researchers about who reads these messages and how often they actually reach students.",
        "doi": "10.1145/3631802.3631813",
        "url": "https://doi.org/10.1145/3631802.3631813",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400716539",
        "year": "2024",
        "title": "Do Students Read Instructor Emails? A Case Study of Intervention Email Open Rates",
        "author": [
            "Angela Zavaleta Bernuy",
            "Runlong Ye",
            "Elexandra Tran",
            "Naaz Sibia",
            "Abhijoy Mandal",
            "Hammad Shaikh",
            "Bogdan Simion",
            "Michael Liut",
            "Andrew Petersen",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "01Zavaleta23"
    },
    {
        "series": "ITiCSE 2024",
        "location": "Milan, Italy",
        "keywords": "computing education, conversational agent, cs1, intelligence concentration, intelligent teaching assistant, intelligent tutoring system, large language models, locally deployable ai, personalized ai agent, retrieval augmented generation, small language models",
        "numpages": "6",
        "pages": "388\u2013393",
        "booktitle": "Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1",
        "abstract": "Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.",
        "doi": "10.1145/3649217.3653554",
        "url": "https://doi.org/10.1145/3649217.3653554",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400706004",
        "year": "2024",
        "title": "Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?",
        "author": [
            "Suqing Liu",
            "Zezhu Yu",
            "Feiran Huang",
            "Yousef Bulbulia",
            "Andreas Bergen",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07SuqingLiu24"
    },
    {
        "series": "DIS '24",
        "location": "IT University of Copenhagen, Denmark",
        "keywords": "Active Learning, Explanation Prompts, Long-Term Memory, Self-Explanations, Student Performance, Text Explanations, Voice Explanations, Voice-based Interaction",
        "numpages": "16",
        "pages": "86\u2013101",
        "booktitle": "Proceedings of the 2024 ACM Designing Interactive Systems Conference",
        "abstract": "This research evaluates voice-based self-explanations as a pedagogical tool in preparation for lectures, assesses user preferences between voice and text, and derives design insights. We report two studies: Study 1, a quasi-experimental field study, with 247 participants divided into voice-based (N = 83), text-based (N = 81), and choice (N = 83) conditions. Study 2 uses semi-structured interviews (N = 16) to explore perceptions of the interaction paradigms in-depth. Results from the first study revealed a general preference for text, though voice users produced longer responses and more topic-related keywords. Over time, the preference for voice increased among students, from 10\\% to 46\\%, when given a choice. Study 2 suggested that factors like social presence contribute to hesitance toward voice-based explanations, with a cognitive load, self-confidence, and performance anxiety also influencing medium preferences. Our findings highlight design recommendations and demonstrate the potential of voice-based self-explanations in educational settings, indicating that mixed interfaces might better meet diverse needs.",
        "doi": "10.1145/3643834.3661596",
        "url": "https://doi.org/10.1145/3643834.3661596",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400705830",
        "year": "2024",
        "title": "Does the Medium Matter? An Exploration of Voice-Interaction for Self-Explanations",
        "author": [
            "Angela Zavaleta Bernuy",
            "Naaz Sibia",
            "Pan Chen",
            "Jessica Jia-Ni Xu",
            "Elexandra Tran",
            "Runlong Ye",
            "Viktoria Pammer-Schindler",
            "Andrew Petersen",
            "Joseph Jay Williams",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07Zavaleta24"
    },
    {
        "series": "DataEd '24",
        "location": "Santiago, AA, Chile",
        "keywords": "Active Learning, Flipped Databases Course, Self-Explanations",
        "numpages": "7",
        "pages": "20\u201326",
        "booktitle": "Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research",
        "abstract": "Self-explanations show promise for engaging students with preparatory materials, yet research into the types of self-explanations submitted in computing is limited. This paper examines student perceptions of self-explanation prompts in a flipped databases course, building on existing research that highlights the advantages of self-explanations in such contexts. We present our findings on students\u2019 perceptions of the utility of self-explanation prompts and analyze the nature of the explanations generated across distinct topics. The results suggest that self-explanations not only facilitate a deeper understanding of the subject matter but also promote the discovery of new connections and examples through rewording explanations. Furthermore, errors within self-explanations offer valuable insights for the early identification of misconceptions.",
        "doi": "10.1145/3663649.3664374",
        "url": "https://doi.org/10.1145/3663649.3664374",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400706783",
        "year": "2024",
        "title": "Exploring Self-Explanations in a Flipped Database Course",
        "author": [
            "Naaz Sibia",
            "Angela Zavaleta Bernuy",
            "Elexandra Tran",
            "Jessica Jia-Ni Xu",
            "Joseph Jay Williams",
            "Andrew Petersen",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Sibia24"
    },
    {
        "series": "ITiCSE-WGR '23",
        "location": "Turku, Finland",
        "keywords": "computer science education research, computing education, equity, evidence, high quality, k-12, post-secondary, primary, research, secondary, standards, tertiary",
        "numpages": "27",
        "pages": "30\u201356",
        "booktitle": "Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "Problem. To investigate and identify promising practices in equitable K-12 and tertiary computer science (CS) education, the capacity for education researchers to conduct this research must be rapidly built globally. Simultaneously, concerns have arisen over the last few years about the quality of research that is being conducted and the lack of research that supports teaching all students computing.Research Question. Our research question for our study was: In what ways can existing research standards and practices inform methodologically sound, equity-enabling computing education research?Methodology. We conducted a concept analysis using existing research and various standards (e.g. European Educational Research Association, Australian Education Research Organisation, American Psychological Association). We then synthesised key features in the context of equity-focused K-12 computing education research.Findings. We present a set of guidelines for general research design that takes into account best practices across the standards that are infused with equity-enabling research practices.Implications. Our guidelines will directly impact future equitable computing education research by providing guidance on conducting high-quality research such that the findings can be aggregated and impact future policy with evidence-based results. Because we have crafted these guidelines to be broadly applicable across a variety of settings, we believe that they will be useful to researchers operating in a variety of contexts.",
        "doi": "10.1145/3623762.3633495",
        "url": "https://doi.org/10.1145/3623762.3633495",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400704055",
        "year": "2023",
        "title": "Conducting Sound, Equity-Enabling Computing Education Research",
        "author": [
            "Monica M. McGill",
            "Sarah Heckman",
            "Christos Chytas",
            "Michael Liut",
            "Vera Kazakova",
            "Ismaila Temitayo Sanusi",
            "Selina Marianna Shah",
            "Claudia Szabo"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12McGill23"
    },
    {
        "series": "ICER '23",
        "location": "Chicago, IL, USA",
        "numpages": "2",
        "pages": "16\u201317",
        "booktitle": "Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2",
        "doi": "10.1145/3568812.3603471",
        "url": "https://doi.org/10.1145/3568812.3603471",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450399753",
        "year": "2023",
        "title": "MSMI1: Towards a Validated SQL Misconceptions Instrument",
        "author": [
            "Daphne Miedema",
            "Michael Liut",
            "George Fletcher",
            "Efthimia Aivaloglou"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "09Miedema23"
    },
    {
        "series": "ITiCSE 2023",
        "location": "Turku, Finland",
        "keywords": "educational technology, voice recording, voice submission",
        "numpages": "2",
        "pages": "585\u2013586",
        "booktitle": "Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2",
        "abstract": "Generating self-explanations has been identified as a successful strategy in helping learners engage with course content and organize what they learn in a structured format. While typing an explanation may allow more structure and formality, explaining by voice can be more natural and help free cognitive resources to focus on learning goals and understanding concepts. As we investigated the effects and students' perceptions of using voice or text to self-explain new course concepts, we failed to find a tool that would meet our needs. We present our work in designing and developing VoiceEx, a submission courseware that allows text and voice input to collect data in both mediums. VoiceEx was created to support a self-explanations intervention for computer science students; however, given its features and the advantages of being able to collect spoken responses, it can be used in a variety of environments. Future refinement of this tool includes artificial intelligence features to better guide students' submissions.",
        "doi": "10.1145/3587103.3595284",
        "url": "https://doi.org/10.1145/3587103.3595284",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400701399",
        "year": "2023",
        "title": "VoiceEx: Voice Submission System for Interventions in Education",
        "author": [
            "Angela Zavaleta Bernuy",
            "Naaz Sibia",
            "Pan Chen",
            "Chloe Huang",
            "Andrew Petersen",
            "Joseph Jay Williams",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Bernuy23"
    },
    {
        "series": "ITiCSE 2023",
        "location": "Turku, Finland",
        "keywords": "educational technology, reflection prompts, self-explanations, voice recording",
        "numpages": "1",
        "pages": "641",
        "booktitle": "Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2",
        "abstract": "In this poster, we present a pilot study investigating the impact of the medium used for self-explanation on students' performance outcomes in a databases course. We did not see notable differences in student performance based on the medium they used for self-explanation. We also note that while most students prefer using text to submit self-explanations, their preferences may differ when they use voice.",
        "doi": "10.1145/3587103.3594188",
        "url": "https://doi.org/10.1145/3587103.3594188",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400701399",
        "year": "2023",
        "title": "Self-Explanation Modality: Effects on Student Performance?",
        "author": [
            "Angela Zavaleta Bernuy",
            "Jessica Jia-Ni Xu",
            "Naaz Sibia",
            "Joseph Jay Williams",
            "Andrew Petersen",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Zavaleta23"
    },
    {
        "series": "EduCHI '23",
        "location": "Hamburg, Germany",
        "keywords": "A/B Testing, HCI Education, Iterative Design",
        "numpages": "6",
        "pages": "43\u201348",
        "booktitle": "Proceedings of the 5th Annual Symposium on HCI Education",
        "abstract": "This paper explores the use of A/B testing as a pedagogical tool for iterative design in HCI classrooms and outlines a vision for experiment-inspired design. The traditional focus on the statistical aspects of A/B testing education has meant that the equally crucial role of iterative design embedded within the experimental process has not received commensurate attention. By incorporating iterative design learning activities that are scaffolded by A/B testing tools, HCI students can gain transferable skills and experience in doing multiple cycles of ideation, prototyping, testing, and evaluation, and simultaneously contribute to continual course improvement. We reconsider the role of experimentation in HCI education as a means for exploring complex design spaces. Drawing from our experience in teaching this approach and conducting education research involving sequences of online controlled experiments, we present examples of how to use A/B testing as a pedagogical tool for iterative design in HCI classrooms.",
        "doi": "10.1145/3587399.3587412",
        "url": "https://doi.org/10.1145/3587399.3587412",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400707377",
        "year": "2023",
        "title": "Using A/B Testing as a Pedagogical Tool for Iterative Design in HCI Classrooms",
        "author": [
            "Mohi Reza",
            "Ilya Musabirov",
            "Nathan Laundry",
            "Michael Liut",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "04Reza23"
    },
    {
        "series": "SIGCSE 2023",
        "location": "Toronto ON, Canada",
        "keywords": "email, open rates, student engagement",
        "numpages": "1",
        "pages": "1363",
        "booktitle": "Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2",
        "abstract": "Instructors often prefer to use email for course communication. The use of emails has been widely discussed in the fields of marketing and behavioural design, but the prevalence of email in education makes it important for instructors to collect metrics on emails to see how students engage with them. One component of emails are the subject lines, which constitute as one of the first things a receiver sees before deciding to open an email. This poster discusses a case study at deploying an email intervention in an online CS1 course. We investigate how the length of subject lines impact the rate at which students open emails of a particular type that prompts them to start their homework early. We aim to share key results to inform instructors how to design their emails to better reach students. Further, we highlight the potential benefits for instructors when collecting and analyzing email engagement data.",
        "doi": "10.1145/3545947.3576307",
        "url": "https://doi.org/10.1145/3545947.3576307",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450394338",
        "year": "2023",
        "title": "Investigating Subject Lines Length on Students' Email Open Rates",
        "author": [
            "Elexandra Tran",
            "Angela Zavaleta Bernuy",
            "Bogdan Simion",
            "Michael Liut",
            "Andrew Petersen",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Tran23"
    },
    {
        "series": "SIGCSE 2023",
        "location": "Toronto ON, Canada",
        "keywords": "adaptive experiments, continuous improvement, field experiments, multiarmed bandits, thompson sampling",
        "numpages": "1",
        "pages": "1279",
        "booktitle": "Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2",
        "abstract": "Drawing inspiration from machine learning and experimentation in product development at leading technology companies, we explore how adaptive experimentation might help in continuous course improvement. In adaptive experiments, as different arms/conditions are deployed to students, data is analyzed and used to change the experience for future students. We discuss an example side-by-side comparison of traditional and adaptive experimentation of self-explanation prompts in online homework problems in a CS1 course. This provides the first step in exploring the future of how this approach can help bridge research and practice in continuous course improvement.",
        "doi": "10.1145/3545947.3576225",
        "url": "https://doi.org/10.1145/3545947.3576225",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450394338",
        "year": "2023",
        "title": "A Case Study in Opportunities for Adaptive Experiments to Enable Rapid Continuous Improvement",
        "author": [
            "Ilya Musabirov",
            "Angela Zavaleta Bernuy",
            "Michael Liut",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Musabirov23"
    },
    {
        "series": "SIGCSE 2023",
        "location": "Toronto ON, Canada",
        "keywords": "adaptive field experiments, computer science education, experimental design, machine learning, multiarmed bandits, statistical analysis",
        "numpages": "1",
        "pages": "1179",
        "booktitle": "Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2",
        "abstract": "Digital experiments can be used in CSedu to test hypotheses about interventions and conditions' efficacy (or inefficacy). This workshop will discuss and deconstruct the design process and analysis for various experiments conducted in CS1. E.g., experiments testing which explanations students find helpful, which emails get them to start homework early, or which webpages effectively encourage and motivate students. This workshop teaches participants how to conduct, interpret, and analyze adaptive field experiments. These adaptive experiments employ machine learning algorithms to analyze experiments during deployment and dynamically shift the allocation of arms/conditions to give future students better conditions more rapidly. Adaptive field experiments can accelerate scientific discovery by enabling more complex experimental designs and increasing statistical power by phasing conditions in and out more efficiently. The workshop is supported by a 5-year NSF grant to build software tools and a digital community, gathering instructors, domain scientists and methodologists to teach them how to run adaptive experiments. The methodological focus includes understanding: (1) which algorithms are best for adaptive experiments that meet domain scientists' needs in specific experimental designs and data sets; (2) which hypothesis tests and Bayesian analyses to choose. Software companies use these innovative methodologies extensively to continuously improve product design. This workshop demonstrates how the same methods can be used in CSedu to improve research rigor and accelerate educational research implementation, ultimately improving student outcomes.",
        "doi": "10.1145/3545947.3569635",
        "url": "https://doi.org/10.1145/3545947.3569635",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450394338",
        "year": "2023",
        "title": "Designing, Deploying, and Analyzing Adaptive Educational Field Experiments",
        "author": [
            "Joseph Jay Williams",
            "Nathan Laundry",
            "Ilya Musabirov",
            "Angela Zavaleta Bernuy",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Williams23"
    },
    {
        "series": "SIGCSE 2023",
        "location": "Toronto ON, Canada",
        "keywords": "cs2, prior experience, self-efficacy, confidence, cs1, prediction",
        "numpages": "7",
        "pages": "889\u2013895",
        "booktitle": "Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1",
        "abstract": "Previous work has reported on the advantageous effects of prior experience in CS1, but it remains unclear whether these effects fade over a sequence of introductory programming courses. Furthermore, while student perceptions suggest that prior experience remains important, studies have reported that a student's expectation of their performance is a more accurate predictor of outcome. We aim to confirm if prior experience (formal or informal) provides short-term and long-term advantages in computing courses or if the advantage fades. Furthermore, we explore whether the expectation of performance is a more accurate predictor of student success than informal and formal prior experience. To explore these questions, we deployed surveys in a CS1 course to gauge students' level of prior experience in programming, prediction of final exam grades, and self-efficacy to succeed in university. Grades from CS1 and CS2 were also collected. We observed a persistent (1-letter grade) gap between the performance of students with no prior experience and those with any experience, but we did not observe a noteworthy gap when comparing student performance based on formal or informal experience. We also observed differences in self-efficacy and retention rates between different levels of prior experience. Lastly, we confirm that success in CS1 can be better reflected and predicted by some controllable factors, such as students' perceptions of ability.",
        "doi": "10.1145/3545945.3569752",
        "url": "https://doi.org/10.1145/3545945.3569752",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450394314",
        "year": "2023",
        "title": "Prior Programming Experience: A Persistent Performance Gap in CS1 and CS2",
        "author": [
            "Giang Bui",
            "Naaz Sibia",
            "Angela Zavaleta Bernuy",
            "Michael Liut",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Bui23"
    },
    {
        "series": "ITiCSE-WGR '23",
        "location": "<conf-loc>, <city>Turku</city>, <country>Finland</country>, </conf-loc>",
        "keywords": "novice programming, llm, large language models, codex, programming, ai, curriculum, github, gpt, code generation, gpt-4, openai, pedagogical practices, llms, generative ai, copilot, cs1, computer programming, chatgpt, artificial intelligence, gpt-3",
        "numpages": "52",
        "pages": "108\u2013159",
        "booktitle": "Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80\\% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.",
        "doi": "10.1145/3623762.3633499",
        "url": "https://doi.org/10.1145/3623762.3633499",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400704055",
        "year": "2023",
        "title": "The Robots Are Here: Navigating the Generative AI Revolution in Computing Education",
        "author": [
            "James Prather",
            "Paul Denny",
            "Juho Leinonen",
            "Brett A. Becker",
            "Ibrahim Albluwi",
            "Michelle Craig",
            "Hieke Keuning",
            "Natalie Kiesler",
            "Tobias Kohn",
            "Andrew Luxton-Reilly",
            "Stephen MacNeil",
            "Andrew Petersen",
            "Raymond Pettit",
            "Brent N. Reeves",
            "Jaromir Savelka"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12Petersen23"
    },
    {
        "series": "ICER '23 V1",
        "location": "Chicago, IL, USA",
        "keywords": "Operating Systems, Problem-based Learning, Productive Failure",
        "numpages": "14",
        "pages": "284\u2013297",
        "booktitle": "Proceedings of the 2023 ACM Conference on International Computing Education Research V.1",
        "abstract": "Motivation and Objectives. Productive Failure is a problem-based learning technique where students attempt to solve a problem before receiving instruction in the topic. By design, students may not find a satisfying solution. Prior studies of Productive Failure in STEM contexts have been conducted in secondary or introductory college settings. Focusing primarily on exploring appropriate analysis and modeling techniques, these studies showed that a Productive Failure approach can lead to greater conceptual knowledge acquisition and transfer capabilities compared to\u202f\u00bbtraditional\u00abDirect Instruction techniques. In this study, we build on these studies along two dimensions: First, we report on the design and evaluation of a Productive Failure intervention in a more advanced undergraduate class: third-year Operating Systems. Second, our intervention targeted a more advanced skill: applying synchronization primitives, rather than selecting appropriate modeling and analysis techniques. Methods. We ran a quasi-experimental study in an undergraduate Operating Systems course to compare the effects of Productive Failure (PF) with Direct Instruction (DI) on students\u2019 learning. To ensure fidelity of implementation as well as to explore different modes of instruction, we ran a pilot study in a remote learning environment. The final study was conducted in an in-person classroom environment. We collected and analyzed both qualitative and quantitative data to gather insights into the students\u2019 problem-solving process and learning outcomes. Results. In line with previous studies, our study did not provide empirical evidence that there was any statistically significant difference with respect to reflection or short-term transfer. While we were able to verify that students in the Productive Failure condition explored a wider spectrum of solution approaches, we could not reliably detect different communication patterns across the conditions. Finally and unlike previous studies, our study was unable to detect longer-term difference in transfer capabilities. Discussion. We failed to observe several of the advantages of Productive Failure over Direct Instruction seen in prior work in other contexts. However, we note several differences in context relative to those earlier studies, including both the complexity of the topics covered and the type of intended learning outcomes. Consequently, our results do not directly contradict earlier findings. Still, they leave room for interpretation and call for further investigation of this instructional approach in more advanced computer science classes.",
        "doi": "10.1145/3568813.3600111",
        "url": "https://doi.org/10.1145/3568813.3600111",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450399760",
        "year": "2023",
        "title": "Exploring Barriers in Productive Failure",
        "author": [
            "Phil Steinhorst",
            "Andrew Petersen",
            "Bogdan Simion",
            "Jan Vahrenhold"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "08Steinhorst23"
    },
    {
        "url": "https://doi.org/10.1007/978-3-031-36336-8_33",
        "isbn": "978-3-031-36336-8",
        "abstract": "We propose and evaluate a question-answering system that uses decomposed prompting to classify and answer student questions on a course discussion board. Our system uses a large language model (LLM) to classify questions into one of four types: conceptual, homework, logistics, and not answerable. This enables us to employ a different strategy for answering questions that fall under different types. Using a variant of GPT-3, we achieve 81{\\%} classification accuracy. We discuss our system's performance on answering conceptual questions from a machine learning course and various failure modes.",
        "pages": "218--223",
        "address": "Cham",
        "publisher": "Springer Nature Switzerland",
        "year": "2023",
        "booktitle": "Artificial Intelligence in Education",
        "title": "Decomposed Prompting to Answer Questions on a Course Discussion Board",
        "editor": "Wang, Ning\nand Rebolledo-Mendez, Genaro\nand Dimitrova, Vania\nand Matsuda, Noboru\nand Santos, Olga C.",
        "author": [
            "Brandon Jaipersaud",
            "Paul Zhang",
            "Jimmy Ba",
            "Andrew Petersen",
            "Lisa Zhang",
            "Michael R. Zhang"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07Petersen23"
    },
    {
        "series": "ITiCSE-WGR '23",
        "location": "<conf-loc>, <city>Turku</city>, <country>Finland</country>, </conf-loc>",
        "keywords": "gender diversity, diversity, computer science, equity, and inclusion, CS, EDI, undergraduate admissions",
        "numpages": "29",
        "pages": "1\u201329",
        "booktitle": "Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "Despite continued efforts to further the participation of women in Computer Science (CS), progress has been limited during the past decades. Recent efforts have been focused on recruitment and retention, with a notable gap in exploring the impact of admissions processes on diversity and inclusion. Through an extensive literature review, contextual analysis of public admissions data from 40 universities across four regions around the world, and qualitative and quantitative analysis on surveys and interviews, we explored the role of admissions in enhancing diversity and inclusion in CS undergraduate programs. Our findings highlight the role of financials, the possible positive effects of explicit advocacy for diversity and inclusion, and the imperative to cultivate a more welcoming and inclusive culture in CS programs.",
        "doi": "10.1145/3623762.3633496",
        "url": "https://doi.org/10.1145/3623762.3633496",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400704055",
        "year": "2023",
        "title": "Enhancing Diversity and Inclusion in Computer Science Undergraduate Programs: The Role of Admissions",
        "author": [
            "Ouldooz Baghban Karimi",
            "Giulia Toti",
            "Mirela Gutica",
            "Rebecca Robinson",
            "Lisa Zhang",
            "James Paterson",
            "Peggy Lindner",
            "Michael O'Dea"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12Zhang23"
    },
    {
        "comment": "<b>Best Paper - Experience Reports and Tools Track</b>",
        "series": "SIGCSE 2023",
        "location": "Toronto ON, Canada",
        "keywords": "wid, wac, wtl, written communication, cs education",
        "numpages": "7",
        "pages": "610\u2013616",
        "booktitle": "Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1",
        "abstract": "Writing skills are often considered unimportant by computer science students and were under-emphasized in our curriculum. We describe our experience embedding CS-specific writing instruction at scale in most of our large, core, first- and second-year Computer Science courses, each with 300-800+ students. Our approach is to collaborate with a writing specialist and a community of course instructors, centralize the management of writing teaching assistants, and introduce a variety of relevant genres and contexts to help students develop and apply writing skills. We outline the institutional support and organization crucial to a project of this scale. In addition, we report on a survey collecting student perception of the writing instruction/assessment. We reflect on quantitative and qualitative evidence of success, as well as the challenges that we faced. We believe that many of these challenges will be common across institutions, particularly those with large courses.",
        "doi": "10.1145/3545945.3569729",
        "url": "https://doi.org/10.1145/3545945.3569729",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450394314",
        "year": "2023",
        "title": "Embedding and Scaling Writing Instruction Across First- and Second-Year Computer Science Courses",
        "author": [
            "Lisa Zhang",
            "Bogdan Simion",
            "Michael Kaler",
            "Amna Liaqat",
            "Daniel Dick",
            "Andi Bergen",
            "Michael Miljanovic",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Zhang23"
    },
    {
        "series": "ITiCSE-WGR '23",
        "location": "<conf-loc>, <city>Turku</city>, <country>Finland</country>, </conf-loc>",
        "keywords": "parson's puzzles, multi-institutional study, parsons puzzles, parson's programming puzzles, multi-institutional multi-national study, parson's problems, parsons problems, multi-national study, code puzzles",
        "numpages": "51",
        "pages": "57\u2013107",
        "booktitle": "Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "Students are often asked to learn programming by writing code from scratch. However, many novices struggle to write code and get frustrated when their code does not work. Parsons problems can reduce the difficulty of a coding problem by providing mixed-up blocks the learner rearranges into the correct order. These mixed-up blocks can include distractor blocks that are not needed in a correct solution. Distractor blocks can include common errors, which may help students learn to recognize and fix such errors. Evidence suggests students find Parsons problems engaging, useful for learning to program, and typically easier and faster to solve than writing code from scratch, but with equivalent learning gains. Most research on Parsons problems prior to this work has been conducted at a single institution. This work addresses the need for replication across multiple contexts.A 2022 ITiCSE Parsons Problems Working Group conducted an extensive literature review of Parsons problems, designed several experimental studies for Parsons problems in Python, and created 'study-in-a-box' materials to help instructors run the experimental studies, but the 2022 working group had only sufficient time to pilot two of these studies.Our 2023 ITiCSE Parsons Problems Working Group reviewed these studies, revised some of the studies, expanded both the programming and natural languages used in some of the studies, created new studies, conducted think-aloud observations on some of the studies, and ran both revised as well as new experimental studies. The think-aloud observations and experimental studies provide evidence for using Parsons problems to help students learn common algorithms such as swap, and the usefulness of distractors in helping students learn to recognize, fix, and avoid common errors. In addition, our 2023 ITiCSE Parsons Problems Working Group reviewed Parsons problem papers published after the 2022 literature review and provided a literature review of multi-national (MIMN) studies conducted in computer science education to better understand the motivations and challenges in performing such MIMN studies.In summary, this article contributes an analysis of recent Parsons problem research papers, an itemization of considerations for MIMN studies, the results from our MIMN studies of Parsons problems, and a discussion of recent and future directions for MIMN studies of Parsons problems and more generally.",
        "doi": "10.1145/3623762.3633498",
        "url": "https://doi.org/10.1145/3623762.3633498",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400704055",
        "year": "2023",
        "title": "Multi-Institutional Multi-National Studies of Parsons Problems",
        "author": [
            "Barbara J. Ericson",
            "Janice L. Pearce",
            "Susan H. Rodger",
            "Andrew Csizmadia",
            "Rita Garcia",
            "Francisco J. Gutierrez",
            "Konstantinos Liaskos",
            "Aadarsh Padiyath",
            "Michael James Scott",
            "David H. Smith",
            "Jayakrishnan M. Warriem",
            "Angela Zavaleta Bernuy"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12Zavaleta23"
    },
    {
        "series": "ITiCSE-WGR '23",
        "location": "<conf-loc>, <city>Turku</city>, <country>Finland</country>, </conf-loc>",
        "keywords": "electives, curriculum, inclusion, women, computing education",
        "numpages": "31",
        "pages": "196\u2013226",
        "booktitle": "Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "Evidence-based strategies suggest ways to reduce the gender gap in computing. For example, elective classes are valuable in enabling students to choose in which directions to expand their computing knowledge in areas aligned with their interests. The availability of electives of interest may also make computing programs of study more meaningful to women. However, research on which elective computing topics are more appealing to women is often class or institution specific. In this study, we investigate differences in enrollment within undergraduate-level elective classes in computing to study differences between women and men. The study combined data from nine institutions from both Western Europe and North America and included 272 different classes with 49,710 student enrollments. These classes were encoded using ACM curriculum guidelines and combined with the enrollment data to build a hierarchical statistical model of factors affecting student choice. Our model shows which elective topics are less popular with all students (including fundamentals of programming languages and parallel and distributed computing), and which elective topics are more popular with women students (including mathematical and statistical foundations, human computer interaction and society, ethics, and professionalism). Understanding which classes appeal to different students can help departments gain insight of student choices and develop programs accordingly. Additionally, these choices can also help departments explore whether some students are less likely to choose certain classes than others, indicating potential barriers to participation in computing.",
        "doi": "10.1145/3623762.3633497",
        "url": "https://doi.org/10.1145/3623762.3633497",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400704055",
        "year": "2023",
        "title": "Modeling Women's Elective Choices in Computing",
        "author": [
            "Steven Bradley",
            "Miranda C. Parker",
            "Rukiye Altin",
            "Lecia Barker",
            "Sara Hooshangi",
            "Thom Kunkeler",
            "Ruth G. Lennon",
            "Fiona McNeill",
            "Julia Minguillon",
            "Jack Parkinson",
            "Svetlana Peltsverger",
            "Naaz Sibia"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12Sibia23"
    },
    {
        "series": "DataEd '22",
        "location": "Philadelphia, PA, USA",
        "keywords": "Active Learning, Long-Term Memory, Computer Science Education, Reflective Prompts, Databases, Student Performance",
        "numpages": "6",
        "pages": "32\u201337",
        "booktitle": "1st International Workshop on Data Systems Education",
        "abstract": "Motivation: Prior literature has identified student reflections as a way to encourage students to express their thoughts in a structured and focused manner. Objectives: Our goal is to examine the impact of reflections in a third year database systems course, which employs an active learning approach and classroom environment. Specifically, we are interested in seeing whether reflecting on key concepts covered in a preparatory component before lecture had an impact on student\u2019s immediate and long-term performance. Methods: Students were divided into two groups, and asked to reflect on different topics after watching lecture videos before completing their homework exercises for 3 weeks. Results: We observed that students who reflected on lecture concepts performed better on homework exercises that covered those same concepts than students who did not reflect on those same concepts. Moreover, students who reflected performed better in subsequent assessments than students who did not reflect at all. Implications: Reflection as a part of the preparatory component in flipped classrooms is a useful component in conceptual understanding. Further research and investigation should be pursued into ways of prompting reflection, and assessing this component in database courses.",
        "doi": "10.1145/3531072.3535323",
        "url": "https://doi.org/10.1145/3531072.3535323",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450393508",
        "year": "2022",
        "title": "The Positive Effects of Using Reflective Prompts in a Database Course",
        "author": [
            "Naaz Sibia",
            "Michael Liut"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Liut22"
    },
    {
        "series": "SIGCSE 2022",
        "location": "Providence, RI, USA",
        "keywords": "surveys, open-ended questions, voice responses, cs1",
        "numpages": "1",
        "pages": "1124",
        "booktitle": "Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2",
        "abstract": "With the widespread usage of mobile devices, users can now choose to provide input through voice or text. As researchers frequently ask students open-ended questions, we want to explore a natural mode to obtain better feedback in surveys. This study details a preliminary study demonstrating the importance of allowing students to choose between voice or text input to respond to surveys. A survey with several open-ended questions was deployed in a CS1 course. Correlations between the gender of the respondent and their method of responding were evaluated. We found that voice responses tended to be longer and preferred more by females relative to male students.",
        "doi": "10.1145/3478432.3499087",
        "url": "https://doi.org/10.1145/3478432.3499087",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450390712",
        "year": "2022",
        "title": "Investigating the Impact of Voice Response Options in Surveys",
        "author": [
            "Pan Chen",
            "Naaz Sibia",
            "Angela Zavaleta Bernuy",
            "Michael Liut",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Liut22"
    },
    {
        "series": "ITiCSE-WGR '22",
        "location": "Dublin, Ireland",
        "keywords": "sequences of programming steps, feedback and hints, learning environments, automated feedback, learning programming",
        "numpages": "21",
        "pages": "95\u2013115",
        "booktitle": "Proceedings of the 2022 Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "Every year, millions of students learn how to write programs. Learning activities for beginners almost always include programming tasks that require a student to write a program to solve a particular problem. When learning how to solve such a task, many students need feedback on their previous actions, and hints on how to proceed. For tasks such as programming, which are most often solved stepwise, the feedback should take the steps a student has taken towards implementing a solution into account, and the hints should help a student to complete or improve a possibly partial solution. This paper investigates how previous research on feedback is translated to when and how to give feedback and hints on steps a student takes when solving a programming task. We have selected datasets consisting of sequences of steps students take when working on a programming problem, and annotated these datasets at those places at which experts would intervene, and how they would intervene. We have used these datasets to compare expert feedback and hints to feedback and hints given by learning environments for programming. Although we have constructed extensive guidelines on when and how to give feedback, we observed plenty of disagreement between experts. We also found several differences between feedback given by experts and learning environments. Experts intervene at specific moments, while in learning environments students have to ask for feedback themselves. The contents of feedback is also different; experts often give (positive) feedback on subgoals, which is not supported by most environments.",
        "doi": "10.1145/3571785.3574124",
        "url": "https://doi.org/10.1145/3571785.3574124",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9798400700101",
        "year": "2022",
        "title": "Towards Giving Timely Formative Feedback and Hints to Novice Programmers",
        "author": [
            "Johan Jeuring",
            "Hieke Keuning",
            "Samiha Marwan",
            "Dennis Bouvier",
            "Cruz Izu",
            "Natalie Kiesler",
            "Teemu Lehtinen",
            "Dominic Lohr",
            "Andrew Peterson",
            "Sami Sarsa"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12Petersen22"
    },
    {
        "series": "LAK22",
        "location": "Online, USA",
        "keywords": "Randomized experiments, Reminder, Embedded experimentation, Procrastination, A/B comparisons",
        "numpages": "12",
        "pages": "107\u2013118",
        "booktitle": "LAK22: 12th International Learning Analytics and Knowledge Conference",
        "abstract": "Email communication between instructors and students is ubiquitous, and it could be valuable to explore ways of testing out how to make email messages more impactful. This paper explores the design space of using emails to get students to plan and reflect on starting weekly homework earlier. We deployed a series of email reminders using randomized A/B comparisons to test alternative factors in the design of these emails, providing examples of an experimental paradigm and metrics for a broader range of interventions. We also surveyed and interviewed instructors and students to compare their predictions about the effectiveness of the reminders with their actual impact. We present our results on which seemingly obvious predictions about effective emails are not borne out, despite there being evidence for further exploring these interventions, as they can sometimes motivate students to attempt their homework more often. We also present qualitative evidence about student opinions and behaviours after receiving the emails, to guide further interventions. These findings provide insight into how to use randomized A/B comparisons in everyday channels such as emails, to provide empirical evidence to test our beliefs about the effectiveness of alternative design choices. ",
        "doi": "10.1145/3506860.3506874",
        "url": "https://doi.org/10.1145/3506860.3506874",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450395731",
        "year": "2022",
        "title": "How Can Email Interventions Increase Students\u2019 Completion of Online Homework? A Case Study Using A/B Comparisons",
        "author": [
            "Angela Zavaleta Bernuy",
            "Ziwen Han",
            "Hammad Shaikh",
            "Qi Yin Zheng",
            "Lisa-Angelique Lim",
            "Anna Rafferty",
            "Andrew Petersen",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Bernuy22"
    },
    {
        "series": "SIGCSE 2022",
        "location": "Providence, RI, USA",
        "keywords": "written communication, cs education",
        "numpages": "7",
        "pages": "161\u2013167",
        "booktitle": "Proceedings of the 53rd ACM Technical Symposium on Computer Science Education",
        "abstract": "This study analyzes common issues in the writing of our upper-year, undergraduate computer science students in timed (e.g. tests) and untimed (e.g. longer assignment reports) scenarios. Our goal is to identify writing issues that should be addressed earlier in the CS curriculum. In collaboration with a writing specialist, we develop and fine-tune a rubric with Grammar, Conciseness, Clarity, Organization, Structure, and Formality as the main categories.  We find, in our writing samples, that grammatical issues (such as punctuation errors or run-on sentences) are common even in a setting where students have ample time to proofread. Other common issues include unclear pronoun antecedents, lacking topic sentences, and other structural and organizational issues. Moreover, we correlate the presence of these issues with the students' grades. We do not find statistically significant correlations between writing skill and grades, and the weak correlations we find depend heavily on the writing context.  We hope that our rubric items and findings are useful for instructors in targeting writing skills that warrant development.",
        "doi": "10.1145/3478431.3499335",
        "url": "https://doi.org/10.1145/3478431.3499335",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450390705",
        "year": "2022",
        "title": "Exploring Common Writing Issues in Upper-Year Computer Science",
        "author": [
            "Rehmat Munir",
            "Francesco Strafforello",
            "Niveditha Kani",
            "Michael Kaler",
            "Bogdan Simion",
            "Lisa Zhang"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Simion22-2"
    },
    {
        "series": "SIGCSE 2022",
        "location": "Providence, RI, USA",
        "keywords": "help supports, cs2, computing education, online learning",
        "numpages": "7",
        "pages": "105\u2013111",
        "booktitle": "Proceedings of the 53rd ACM Technical Symposium on Computer Science Education",
        "abstract": "With the shift to online delivery, instructors looked to provide comparable help supports for students, especially for first-year learners who need timely assistance the most. Our work aims to understand student help seeking behavior and perception of getting help in an online CS2 course.First, we analyze how much students ask for help and perceive to get help in several help support components: lectures, labs, instructor office hours, and on the discussion board. We find that while students take advantage of all help resources, the discussion board is predominantly the main source of help, while instructor office hours run into scalability problems. Secondly, we explore whether asking for and getting help are correlated with grades and find an inverted-U quadratic relationship in both cases. This indicates that low-performing and high-performing students ask for the least help and perceive to get the least help in each of the help support components. Finally, in each help context, we investigate which categories of questions students seek help the most with, and who students rely on most for help.Our analysis is intended to help educators better understand how to support first-year students in an online course and we hope that our findings are also useful for help support planning once in-person learning resumes.",
        "doi": "10.1145/3478431.3499369",
        "url": "https://doi.org/10.1145/3478431.3499369",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450390705",
        "year": "2022",
        "title": "Help Supports during Online Delivery: Student Perception and Lessons Learnt from an Online CS2",
        "author": [
            "Andrew Jiang",
            "Bogdan Simion"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Simion22-1"
    },
    {
        "series": "Koli Calling '21",
        "location": "Joensuu, Finland",
        "keywords": "SQL Automarking, Partial Marking, String Regularities, String Similarity, Database Course Tools, Student Feedback Enhancement",
        "numpages": "3",
        "articleno": "37",
        "booktitle": "21st Koli Calling International Conference on Computing Education Research",
        "abstract": "This work introduces and demonstrates the viability of a novel SQL automarking tool (\u201cSQAM\u201d) that: (1) provides a fair grade to the student, one which matches the student\u2019s effort and understanding of the course material, and (2) to provide personalized feedback, allowing the student to remain engaged in the material and learn from their mistakes while still being in that headspace. Additionally, we strive to ensure that our tool maintains the same standards (grade and feedback) that a highly qualified member of teaching staff would produce, so we compare and contrast our automarker\u2019s results to that of teaching assistants over several historic offerings of the same database course at a large research intensive public institution, while reducing the grading time, thus enabling the teaching staff to channel more time into instruction. Furthermore, we describe SQAM\u2019s design and our model which applies the aggregate result of four different string similarity metrics to compute solution similarity in conjunction with our discretization process to fairly evaluate a student\u2019s submission. Our results show that SQAM produces very similar grades to those which were historically given by teaching assistants. ",
        "doi": "10.1145/3488042.3489970",
        "url": "https://doi.org/10.1145/3488042.3489970",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450384889",
        "year": "2021",
        "title": "Building a Better SQL Automarker for Database Courses",
        "author": [
            "Muyu Wang",
            "Naaz Sibia",
            "Ilir Dema",
            "Michael Liut",
            "Carlos An\u00edbal Su\u00e1rez"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11Liut20"
    },
    {
        "series": "Koli Calling '21",
        "location": "Joensuu, Finland",
        "keywords": "retention, spatial skills, socioeconomic status, CS1, gender",
        "numpages": "10",
        "articleno": "4",
        "booktitle": "21st Koli Calling International Conference on Computing Education Research",
        "abstract": "Motivation Prior studies have established that training spatial skills may improve outcomes in computing courses. Very few of these studies have, however, explored the impact of spatial skills training on women or examined its relationship with other factors commonly explored in the context of academic performance, such as socioeconomic background and self-efficacy. Objectives In this study, we report on a spatial skills intervention deployed in a computer programming course (CS1) in the first year of a post-secondary program. We explore the relationship between various demographic factors, course performance, and spatial skills ability at both the beginning and end of the term. Methods Data was collected using a combination of demographic surveys, existing self-efficacy and CS1 content instruments, and the Revised PVST:R spatial skills assessment. Spatial skills were evaluated both at the beginning of the term and at the end, after spatial skills training was provided. Results While little evidence was found to link spatial skills to socioeconomic status or self-efficacy, both gender identity and previous experience in computing were found to be correlated to spatial skills ability at the start of the course. Women initially recorded lower spatial skills ability, but after training, the distribution of spatial skills scores for women approached that of men. Discussion These findings suggest that, if offered early enough, spatial skills training may be able to remedy some differences in background that impact performance in computing courses. ",
        "doi": "10.1145/3488042.3488049",
        "url": "https://doi.org/10.1145/3488042.3488049",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450384889",
        "year": "2021",
        "title": "Spatial Skills and Demographic Factors in CS1",
        "author": [
            "Anna Ly",
            "Jack Parkinson",
            "Quintin Cutts",
            "Michael Liut",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11ly21"
    },
    {
        "numpages": "12",
        "pages": "18\u201329",
        "month": "nov",
        "journal": "ACM Inroads",
        "doi": "10.1145/3494574",
        "url": "https://doi.org/10.1145/3494574",
        "issn": "2153-2184",
        "number": "4",
        "volume": "12",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "issue_date": "December 2021",
        "year": "2021",
        "title": "Practice Report: Six Studies of Spatial Skills Training in Introductory Computer Science",
        "author": [
            "Jack Parkinson",
            "Ryan Bockmon",
            "Quintin Cutts",
            "Michael Liut",
            "Andrew Petersen",
            "Sheryl Sorby"
        ],
        "ENTRYTYPE": "article",
        "ID": "12parkinson21"
    },
    {
        "doi": "10.1145/3450329.3476855",
        "url": "https://doi.org/10.1145/3450329.3476855",
        "year": "2021",
        "pages": "9--14",
        "booktitle": "Proceedings of the 22st Annual Conference on Information Technology Education",
        "author": [
            "Anna Ly",
            "John Edwards",
            "Michael Liut",
            "Andrew Petersen"
        ],
        "title": "Revisiting Syntax Exercises in CS1",
        "ENTRYTYPE": "inproceedings",
        "ID": "10ly2021revisiting"
    },
    {
        "doi": "10.1007/978-3-030-78270-2_75",
        "url": "https://link.springer.com/chapter/10.1007/978-3-030-78270-2_75",
        "isbn": "978-3-030-78270-2",
        "abstract": "Adaptive experiments can increase the chance that current students obtain better outcomes from a field experiment of an instructional intervention. In such experiments, the probability of assigning students to conditions changes while more data is being collected, so students can be assigned to interventions that are likely to perform better. Digital educational environments lower the barrier to conducting such adaptive experiments, but they are rarely applied in education. One reason might be that researchers have access to few real-world case studies that illustrate the advantages and disadvantages of these experiments in a specific context. We evaluate the effect of homework email reminders in students by conducting an adaptive experiment using the Thompson Sampling algorithm and compare it to a traditional uniform random experiment. We present this as a case study on how to conduct such experiments, and we raise a range of open questions about the conditions under which adaptive randomized experiments may be more or less useful.",
        "pages": "422--426",
        "address": "Cham",
        "publisher": "Springer International Publishing",
        "year": "2021",
        "booktitle": "Artificial Intelligence in Education",
        "title": "Using Adaptive Experiments to Rapidly Help Students",
        "editor": "Roll, Ido\nand McNamara, Danielle\nand Sosnovsky, Sergey\nand Luckin, Rose\nand Dimitrova, Vania",
        "author": [
            "Angela Zavaleta-Bernuy",
            "Qi Yin Zheng",
            "Hammad Shaikh",
            "Jacob Nogas",
            "Anna Rafferty",
            "Andrew Petersen",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Zavaleta21"
    },
    {
        "series": "L@S '21",
        "location": "Virtual Event, Germany",
        "keywords": "field deployment, online learning, A/B testing, intervention, randomized experiments, personalization",
        "numpages": "4",
        "pages": "235\u2013238",
        "booktitle": "Proceedings of the Eighth ACM Conference on Learning @ Scale",
        "abstract": "In online asynchronous learning environments, students are assigned exercises, but it is not clear how to incorporate the kinds of actions an in-person tutor might take such as explaining, providing more practice, prompting for reflection, and motivating. We explore approaches to adding \"Drop-Downs'' that appear after a student submits an answer and that contain additional information to support learning. We conducted randomized A/B experiments exploring the impact of these Drop-Downs on student learning in the online portion of a flipped CS1 course. The deployed Drop-Downs in this course provided explanations, reflective prompts, additional problems, and motivational messages. The results suggest that students benefit from various Drop-Downs in different contexts, indicating the possibility of personalizing content based on the student's state. We discuss the resulting design implications of Drop-Downs in online learning systems.",
        "doi": "10.1145/3430895.3460145",
        "url": "https://doi.org/10.1145/3430895.3460145",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450382151",
        "year": "2021",
        "title": "Exploring Additional Personalized Support While Attempting Exercise Problems in Online Learning Platforms",
        "author": [
            "Yuya Asano",
            "Madhurima Dutta",
            "Trisha Thakur",
            "Jaemarie Solyst",
            "Stephanie Cristea",
            "Helena Jovic",
            "Andrew Petersen",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Asano21"
    },
    {
        "series": "SIGCSE '21",
        "location": "Virtual Event, USA",
        "keywords": "A/B comparisons, procrastination, reminders, CS1, email",
        "numpages": "7",
        "pages": "921\u2013927",
        "booktitle": "Proceedings of the 52nd ACM Technical Symposium on Computer Science Education",
        "abstract": "Procrastination by students may lead to adverse outcomes such as a focus on completion rather than learning or even a failure to complete learning tasks. One common method for motivating students and reducing procrastination is to send reminders with hints and study strategies, but it's not clear if these messages are effective or when is the best time to send them. Randomized A/B comparisons could be used to try different reminders or alternative ideas about how best to get students to start work earlier and, crucially, to measure the impact of these interventions on behaviour. This paper describes an A/B comparison of reminder emails set in a large CS1 course at a research-focused North American u\nniversity. We found evidence that the email interventions caused a higher proportion of students to attempt the online h\nomework but did not see evidence that these particular emails got students to start early, irrespective of changes to the timing of the reminder. More broadly, these findings illustrate how to use A/B comparisons in educational settings to test ideas about how to help students, and demonstrate the value of using randomized A/B comparisons, even when evaluating actions that seem obviously beneficial, such as reminder emails.",
        "doi": "10.1145/3408877.3432427",
        "url": "https://doi.org/10.1145/3408877.3432427",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450380621",
        "year": "2021",
        "title": "Investigating the Impact of Online Homework Reminders Using Randomized A/B Comparisons",
        "author": [
            "Angela Zavaleta Bernuy",
            "Qi Yin Zheng",
            "Hammad Shaikh",
            "Andrew Petersen",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Petersen21-2"
    },
    {
        "series": "SIGCSE '21",
        "location": "Virtual Event, USA",
        "keywords": "online learning, inverted classroom, gaming the system, procrastination",
        "numpages": "7",
        "pages": "789\u2013795",
        "booktitle": "Proceedings of the 52nd ACM Technical Symposium on Computer Science Education",
        "abstract": "Engaged preparation and study in combination with lectures are important for all courses but are particularly critical for online, hybrid, and inverted classrooms. Many instructors use online systems to deliver new course content and exercises, but students often delay assignments or game these systems (e.g., guessing on multiple-choice questions), often to the detriment of their learning. In an inverted CS1 course, many students self-reported high rates of gaming-the-system behavior, so we examine survey data to identify factors that contribute to engagement in these maladaptive behaviours. We supplement that analysis with interview data to gain a deeper understanding of the situation. We also implemented and evaluated a previously reported online intervention aimed at reducing gaming behavior. Unlike prior work, our intervention did not have a significant effect on guessing behavior. We discuss why the factors we identified might explain this result, as well as suggest future work to improve our understanding of gaming behaviours and inform the design of systems that encourage effective learning.",
        "doi": "10.1145/3408877.3432440",
        "url": "https://doi.org/10.1145/3408877.3432440",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450380621",
        "year": "2021",
        "title": "Procrastination and Gaming in an Online Homework System of an Inverted CS1",
        "author": [
            "Jaemarie Solyst",
            "Trisha Thakur",
            "Madhurima Dutta",
            "Yuya Asano",
            "Andrew Petersen",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Petersen21"
    },
    {
        "series": "ITiCSE '21",
        "location": "Virtual Event, Germany",
        "keywords": "group work, computer science education, active learning, CS2",
        "numpages": "7",
        "pages": "25\u201331",
        "booktitle": "Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1",
        "abstract": "Most active learning methods aim to engage students in collaborative problem-solving. While active learning and collaboration benefits are indisputable, more investigation is needed to understand student engagement in group activities. This qualitative study investigates the student perspective on group work in a CS2 inverted classroom, to better understand the learner mindset and identify potential barriers or conduits for collaborative engagement. We conducted 30-45 minute interviews with 30 participants from six sections of CS2, with five sections being scheduled in an Active Learning Classroom (ALC) and one in a traditional lecture hall, all taught in the same inverted model and using the same in-class activities. A multitude of facets of student behavior or engagement in group work and interactions with peers were identified via emergent coding. We classified emerging themes into higher-order categories which subsume semantically-related themes, forming a hierarchy with the top-level categories being Perceived Utility and Social Environment. This classification is intended to provide insight to educators seeking to better engage students in active learning via collaborative in-class activities.",
        "doi": "10.1145/3430665.3456359",
        "url": "https://doi.org/10.1145/3430665.3456359",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450382144",
        "year": "2021",
        "title": "A Qualitative Study of Group Work and Participation Dynamics in a CS2 Active Learning Environment",
        "author": [
            "Rutwa Engineer",
            "Ayesha Naeem Syeda",
            "Bogdan Simion"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Engineer21"
    },
    {
        "url": "https://cssplice.github.io/LAS20/proc/SPLICE_2020_LS_paper_9.pdf",
        "numpage": "6",
        "year": "2020",
        "booktitle": "Proceedings of the 6th SPLICE Workshop at L@S",
        "title": "Using Discussion Board Data to Hire Teaching Assistants",
        "author": [
            "Arnaud Deza",
            "Haocheng Hu",
            "Vaishvik Maisuria",
            "Michael Liut",
            "Andrew Petersen",
            "Bogdan Simion"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "08Liut20"
    },
    {
        "series": "ITiCSE-WGR '20",
        "location": "Trondheim, Norway",
        "keywords": "collusion, academic integrity, plagiarism, code similarity detection",
        "numpages": "19",
        "pages": "1\u201319",
        "booktitle": "Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education",
        "doi": "10.1145/3437800.3439201",
        "url": "https://doi.org/10.1145/3437800.3439201",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450382939",
        "year": "2020",
        "title": "Choosing Code Segments to Exclude from Code Similarity Detection",
        "author": [
            "Simon",
            "Oscar Karnalim",
            "Judy Sheard",
            "Ilir Dema",
            "Amey Karkare",
            "Juho Leinonen",
            "Michael Liut",
            "Renee McCauley"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Liut20"
    },
    {
        "series": "ITiCSE-WGR '20",
        "location": "Trondheim, Norway",
        "keywords": "notional machines, computing education",
        "numpages": "30",
        "pages": "21\u201350",
        "booktitle": "Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education",
        "abstract": "This report defines notional machines (NMs), and provides a series of definitional characteristics by which they may be identified. Over several sections, it includes a first-hand report of the origin of NMs, reports a systematic literature review to track the use and development of the concept, and presents a small collection of examples collected through interviews with experienced teachers. Additionally, the report presents NMs in a common format, and makes some preliminary explorations of their use in practice, including examples of instructors using multiple NMs in sequence. Approach and method are fully detailed in evidential appendices, to support replication of results and adoption/adaptation of practice.",
        "doi": "10.1145/3437800.3439202",
        "url": "https://doi.org/10.1145/3437800.3439202",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450382939",
        "year": "2020",
        "title": "Notional Machines in Computing Education: The Education of Attention",
        "author": [
            "Sally Fincher",
            "Johan Jeuring",
            "Craig S. Miller",
            "Peter Donaldson",
            "Benedict du Boulay",
            "Matthias Hauswirth",
            "Arto Hellas",
            "Felienne Hermans",
            "Colleen Lewis",
            "Andreas Muhling",
            "Janice L. Pearce",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06Petersen20-2"
    },
    {
        "series": "Koli Calling '20",
        "location": "Koli, Finland",
        "keywords": "factor analysis, careers, mathematics, curriculum, identity",
        "numpages": "10",
        "articleno": "17",
        "booktitle": "Koli Calling '20: Proceedings of the 20th Koli Calling International Conference on Computing Education Research",
        "abstract": "Mathematics is at the heart of computer science as a discipline, yet not all students appreciate the relevance and importance of mathematics in a computing degree. Recent work presented a hypothesis that a student\u2019s career inclinations may impact their view towards the value of learning mathematics, and thus their course selections. However, empirical support for this theory has previously been limited to a single institution in which students are required to include mathematics as part of their degree. In this work, we conduct a replication study in a different institutional context where mathematics is not a strict requirement for computer science students. We find robust support for the previously hypothesized relationship between career inclinations and perceptions of mathematics, and a strongly stated desire from students that the mathematics they learn should be more clearly connected and relevant to computer science. ",
        "doi": "10.1145/3428029.3428046",
        "url": "https://doi.org/10.1145/3428029.3428046",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450389211",
        "year": "2020",
        "title": "Mathematics, Computer Science and Career Inclinations \u2014 A Multi-Institutional Exploration",
        "author": [
            "Jacqueline Whalley",
            "Andrew Petersen",
            "Paul Denny"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11Petersen20"
    },
    {
        "series": "ICER \u201920",
        "location": "Virtual Event, New Zealand",
        "keywords": "factor analysis, introductory programming, self-efficacy",
        "numpages": "12",
        "pages": "158\u2013169",
        "booktitle": "Proceedings of the 2020 ACM Conference on International Computing Education Research",
        "doi": "10.1145/3372782.3406281",
        "url": "https://doi.org/10.1145/3372782.3406281",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450370929",
        "year": "2020",
        "title": "Revisiting Self-Efficacy in Introductory Programming",
        "author": [
            "Phil Steinhorst",
            "Andrew Petersen",
            "Jan Vahrenhold"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "08Steinhorst20"
    },
    {
        "url": "https://drive.google.com/file/d/1SNTCvsRy-1YRSAXo1UYFu2IjKIK-CphN/view?usp=sharing",
        "numpage": "6",
        "year": "2020",
        "booktitle": "Educational Data Mining in Computer Science Education (CSEDM) Workshop @ EDM",
        "title": "Effects of Explanations and Additional Practice on Short versus Long Term Learning in Online Programming Homework",
        "author": [
            "Ben Prystawski",
            "Jacob Nogas",
            "Andrew Petersen",
            "Joseph Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07Prystawski20"
    },
    {
        "series": "ITiCSE \u201920",
        "location": "Trondheim, Norway",
        "keywords": "programming process data, compiler error metrics, data sharing",
        "numpages": "7",
        "pages": "356\u2013362",
        "booktitle": "Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education",
        "doi": "10.1145/3341525.3387373",
        "url": "https://doi.org/10.1145/3341525.3387373",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450368742",
        "year": "2020",
        "author": [
            "Thomas Price",
            "David Hovemeyer",
            "Kelly Rivers",
            "Austin Bart",
            "Ge Gao",
            "Ayaan M. Kazerouni",
            "Brett Becker",
            "Andrew Petersen",
            "Luke Gusukuma",
            "Stephen H. Edwards",
            "David Babcock"
        ],
        "title": "ProgSnap2: A Flexible Format for Programming Process Data",
        "ENTRYTYPE": "inproceedings",
        "ID": "06Petersen20"
    },
    {
        "url": "https://cssplice.github.io/LAS20/proc/SPLICE_2020_LS_paper_2.pdf",
        "numpage": "3",
        "year": "2020",
        "booktitle": "Proceedings of the 6th SPLICE Workshop at L@S",
        "title": "Recommending Personalized Review Questions using Collaborative Filtering",
        "author": [
            "Zain Kazmi",
            "Wafiqah Raisa",
            "Harsh Jhunjhunwala",
            "Lisa Zhang"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "08Kazmi20"
    },
    {
        "url": "https://cssplice.github.io/LAS20/proc/SPLICE_2020_LS_paper_3.pdf",
        "numpage": "3",
        "year": "2020",
        "booktitle": "Proceedings of the 6th SPLICE Workshop at L@S",
        "title": "CS1 Programming Feedback with Bug Localization",
        "author": [
            "Lucas Roy",
            "Haotian Yang",
            "Lisa Zhang"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "08Roy20"
    },
    {
        "series": "SIGCSE \u201920",
        "location": "Portland, OR, USA",
        "keywords": "active learning classrooms, computer science education, inverted classroom",
        "numpages": "7",
        "pages": "93\u201399",
        "booktitle": "Proceedings of the 51st ACM Technical Symposium on Computer Science Education",
        "doi": "10.1145/3328778.3366872",
        "url": "https://doi.org/10.1145/3328778.3366872",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450367936",
        "year": "2020",
        "title": "Analyzing the Effects of Active Learning Classrooms in CS2",
        "author": [
            "Ayesha Naeem Syeda",
            "Rutwa Engineer",
            "Bogdan Simion"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "01Simion20"
    },
    {
        "series": "ITiCSE-WGR \u201919",
        "location": "Aberdeen, Scotland Uk",
        "keywords": "computing education, epistemology, learning theory",
        "numpages": "21",
        "pages": "89\u2013109",
        "booktitle": "Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education",
        "doi": "10.1145/3344429.3372504",
        "url": "https://doi.org/10.1145/3344429.3372504",
        "address": "New York, NY, USA",
        "publisher": "Association for Computing Machinery",
        "isbn": "9781450375672",
        "year": "2019",
        "title": "Review and Use of Learning Theories within Computer Science Education Research: Primer for Researchers and Practitioners",
        "author": [
            "Claudia Szabo",
            "Nickolas Falkner",
            "Andrew Petersen",
            "Heather Bort",
            "Kathryn Cunningham",
            "Peter Donaldson",
            "Arto Hellas",
            "James Robinson",
            "Judy Sheard"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12Szabo19"
    },
    {
        "year": "2019",
        "url": "https://people.engr.ncsu.edu/twprice/website/files/CSEDM%202019%20ProgSnap2.pdf",
        "booktitle": "Proceedings of the 2nd Educational Data Mining in Computer Science Education Workshop",
        "title": "ProgSnap 2: A Flexible Format for Programming Snapshot Data",
        "author": [
            "Thomas Price",
            "David Hovemeyer",
            "Kelly Rivers",
            "Austin Cory Bart",
            "Andrew Petersen",
            "Brett Becker",
            "Jason Lefever"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "04Petersen19"
    },
    {
        "keywords": "identity, mathematics",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3287416",
        "doi": "10.1145/3287324.3287416",
        "url": "http://doi.acm.org/10.1145/3287324.3287416",
        "numpages": "7",
        "pages": "1032--1038",
        "location": "Minneapolis, MN, USA",
        "isbn": "978-1-4503-5890-3",
        "year": "2019",
        "series": "SIGCSE '19",
        "booktitle": "Proceedings of the 50th ACM Technical Symposium on Computer Science Education",
        "title": "A Survey-based Exploration of Computer Science Student Perspectives on Mathematics",
        "author": [
            "Nikki Sigurdson",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Petersen19"
    },
    {
        "url": "https://scholarspace.manoa.hawaii.edu/handle/10125/60204",
        "publisher": "Computer Society Press",
        "numpages": "6",
        "year": "2019",
        "series": "HICCS-52",
        "booktitle": "Proceedings of the 52nd Annual Hawaii International Conference on System Sciences",
        "author": [
            "Petri Ihantola",
            "Andrew Petersen"
        ],
        "title": "Code Complexity in Introductory Programming Courses",
        "ENTRYTYPE": "inproceedings",
        "ID": "01Ihantola19"
    },
    {
        "year": "2019",
        "pages": "9751--9753",
        "volume": "33",
        "booktitle": "Proceedings of the AAAI Conference on Artificial Intelligence",
        "author": [
            "Todd W. Neller",
            "Raja Sooriamurthi",
            "Michael Guerzhoy",
            "Lisa Zhang",
            "Paul Talaga",
            "Christopher Archibald",
            "Adam Summerville",
            "Joseph Osborn",
            "Cinjon Resnick",
            "Avital Oliver",
            "others"
        ],
        "title": "Model AI Assignments 2019",
        "ENTRYTYPE": "inproceedings",
        "ID": "02Zhang19"
    },
    {
        "keywords": "CS1, industry professionals, video-conferenced classroom visits",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3309511",
        "doi": "10.1145/3300115.3309511",
        "url": "http://doi.acm.org/10.1145/3300115.3309511",
        "numpages": "7",
        "pages": "222--228",
        "location": "Chengdu,Sichuan, China",
        "isbn": "978-1-4503-6259-7",
        "year": "2019",
        "series": "CompEd '19",
        "booktitle": "Proceedings of the ACM Conference on Global Computing Education",
        "title": "Experience Report: Mini Guest Lectures in a CS1 Course via Video Conferencing",
        "author": [
            "Lisa Zhang",
            "Michelle Craig",
            "Mark Kazakevich",
            "Joseph Jay Williams"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "05Zhang19"
    },
    {
        "keywords": "analytics, educational data mining, learning analytics, literature review, mapping study, performance, prediction",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3295783",
        "doi": "10.1145/3293881.3295783",
        "url": "http://doi.acm.org/10.1145/3293881.3295783",
        "numpages": "25",
        "pages": "175--199",
        "location": "Larnaca, Cyprus",
        "isbn": "978-1-4503-6223-8",
        "year": "2018",
        "series": "ITiCSE 2018 Companion",
        "booktitle": "Proceedings Companion of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education",
        "title": "Predicting Academic Performance: A Systematic Literature Review",
        "author": [
            "Arto Hellas",
            "Petri Ihantola",
            "Andrew Petersen",
            "Vangel V. Ajanovski",
            "Mirela Gutica",
            "Timo Hynninen",
            "Antti Knutas",
            "Juho Leinonen",
            "Chris Messom",
            "Soohyun Nam Liao"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "12Hellas18"
    },
    {
        "keywords": "CS1, grit, learning analytics, psychometric factors",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3279743",
        "doi": "10.1145/3279720.3279743",
        "url": "http://doi.acm.org/10.1145/3279720.3279743",
        "numpages": "5",
        "articleno": "23",
        "pages": "23:1--23:5",
        "location": "Koli, Finland",
        "isbn": "978-1-4503-6535-2",
        "year": "2018",
        "series": "Koli Calling '18",
        "booktitle": "Proceedings of the 18th Koli Calling International Conference on Computing Education Research",
        "title": "An Exploration of Grit in a {CS1} Context",
        "author": [
            "Nikki Sigurdson",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11Petersen18-1"
    },
    {
        "keywords": "CS1, Java programming, computer science education, interactive learning technologies, worked examples",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3279726",
        "doi": "10.1145/3279720.3279726",
        "url": "http://doi.acm.org/10.1145/3279720.3279726",
        "numpages": "9",
        "articleno": "5",
        "pages": "5:1--5:9",
        "isbn": "978-1-4503-6535-2",
        "location": "Koli, Finland",
        "year": "2018",
        "series": "Koli Calling '18",
        "booktitle": "Proceedings of the 18th Koli Calling International Conference on Computing Education Research",
        "title": "{PCEX}: Interactive Program Construction Examples for Learning Programming",
        "author": [
            "Kamil Akhusyinoglu, Andrew Petersen, Christian D. Schunn, Roya Hosseini",
            "Peter Brusilovsky"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11Petersen18-2"
    },
    {
        "keywords": "Active Learning, CS Education, Clicker Questions, Peer Instruction",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3197144",
        "doi": "10.1145/3197091.3197144",
        "url": "http://doi.acm.org/10.1145/3197091.3197144",
        "numpages": "6",
        "pages": "308--313",
        "location": "Larnaca, Cyprus",
        "isbn": "978-1-4503-5707-4",
        "year": "2018",
        "series": "ITiCSE 2018",
        "booktitle": "Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education",
        "author": [
            "Cynthia Taylor",
            "Jaime Spacco",
            "David P. Bunde",
            "Andrew Petersen",
            "Soohyun Nam Liao",
            "Leo Porter"
        ],
        "title": "A Multi-institution Exploration of Peer Instruction in Practice",
        "ENTRYTYPE": "inproceedings",
        "ID": "07Petersen18-2"
    },
    {
        "keywords": "CS1, code review, peer review, studio-based learning",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3205832",
        "doi": "10.1145/3197091.3205832",
        "url": "http://doi.acm.org/10.1145/3197091.3205832",
        "numpages": "2",
        "pages": "354--355",
        "location": "Larnaca, Cyprus",
        "isbn": "978-1-4503-5707-4",
        "year": "2018",
        "series": "ITiCSE 2018",
        "booktitle": "Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education",
        "author": [
            "Andrew Petersen",
            "Dan Zingaro"
        ],
        "title": "Code Reviews in Large, First Year Courses",
        "ENTRYTYPE": "inproceedings",
        "ID": "07Petersen18-1"
    },
    {
        "comment": "<b>Honorable Mention (Top 5%).</b>",
        "keywords": "badges, gamification, peerwise, points, self-testing",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3173885",
        "doi": "10.1145/3173574.3173885",
        "url": "http://doi.acm.org/10.1145/3173574.3173885",
        "numpages": "13",
        "articleno": "311",
        "pages": "311:1--311:13",
        "location": "Montreal QC, Canada",
        "isbn": "978-1-4503-5620-6",
        "year": "2018",
        "series": "CHI '18",
        "booktitle": "Proceedings of the 2018 {CHI} Conference on Human Factors in Computing Systems",
        "title": "Empirical Support for a Causal Relationship Between Gamification and Learning Outcomes",
        "author": [
            "Paul Denny",
            "Fiona McDonald",
            "Ruth Empson",
            "Philip Kelly",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "04Petersen:2018"
    },
    {
        "keywords": "academic integrity, collusion, computing education, plagiarism, programming education",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3160502",
        "doi": "10.1145/3160489.3160502",
        "url": "http://doi.acm.org/10.1145/3160489.3160502",
        "numpages": "10",
        "pages": "113--122",
        "location": "Brisbane, Queensland, Australia",
        "isbn": "978-1-4503-6340-2",
        "year": "2018",
        "series": "ACE '18",
        "booktitle": "Proceedings of the 20th Australasian Computing Education Conference",
        "title": "Informing Students about Academic Integrity in Programming",
        "author": [
            "Simon",
            "Judy Sheard",
            "Michael Morgan",
            "Andrew Petersen",
            "Amber Settle",
            "Jane Sinclair"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "01Simon18"
    },
    {
        "keywords": "curriculum, identity, mathematics",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3141888",
        "doi": "10.1145/3141880.3141888",
        "url": "http://doi.acm.org/10.1145/3141880.3141888",
        "numpages": "10",
        "pages": "108--117",
        "location": "Koli, Finland",
        "isbn": "978-1-4503-5301-4",
        "year": "2017",
        "series": "Koli Calling '17",
        "booktitle": "Proceedings of the 17th Koli Calling Conference on Computing Education Research",
        "title": "Student Perspectives on Mathematics in Computer Science",
        "author": [
            "Nikki Sigurdson",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11Sigurdson17"
    },
    {
        "keywords": "assessment, compound assessment, concept inventory, cs1, exam, introductory programming, iticse working group, learning, learning objectives, learning outcomes, mastery, novice programming, questions",
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "acmid": "3174784",
        "doi": "10.1145/3174781.3174784",
        "url": "http://doi.acm.org/10.1145/3174781.3174784",
        "numpages": "23",
        "pages": "47--69",
        "location": "Bologna, Italy",
        "isbn": "978-1-4503-5627-5",
        "year": "2017",
        "series": "ITiCSE-WGR '17",
        "booktitle": "Proceedings of the 2017 ITiCSE Conference on Working Group Reports",
        "title": "Developing Assessments to Determine Mastery of Programming Fundamentals",
        "author": [
            "Andrew Luxton-Reilly",
            "Brett A. Becker",
            "Yingjun Cao",
            "Roger McDermott",
            "Claudio Mirolo",
            "Andreas Muhling",
            "Andrew Petersen",
            "Kate Sanders",
            "Simon",
            "Jacqueline Whalley"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "08Luxton-Reilly17"
    },
    {
        "address": "New York, NY, USA",
        "publisher": "ACM",
        "pages": "146--151",
        "doi": "10.1145/3059009.3059033",
        "url": "https://doi.org/10.1145/3059009.3059033",
        "numpages": "6",
        "location": "Bologna, Italy",
        "year": "2017",
        "series": "ITICSE '17",
        "booktitle": "Proceedings of the 2017 {ACM} Conference on Innovation and Technology in Computer Science Education",
        "title": "Examining a Student-Generated Question Activity Using Random Topic Assignment",
        "author": [
            "Paul Denny",
            "Ewan Tempero",
            "Dawn Garbett",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07Denny17"
    },
    {
        "comment": "<b>Recognized as a SIGCSE Exemplary (Top 25%) Paper</b>",
        "keywords": "CS1, at-risk students, educational data mining, introductory programming, learning analytics, replication, reproduction, source code snapshot analysis",
        "acmid": "3017792",
        "doi": "10.1145/3017680.3017792",
        "url": "http://doi.acm.org/10.1145/3017680.3017792",
        "numpages": "6",
        "pages": "111--116",
        "location": "Seattle, Washington, USA",
        "isbn": "978-1-4503-4698-6",
        "year": "2017",
        "series": "SIGCSE '17",
        "booktitle": "Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education",
        "title": "Evaluating Neural Networks As a Method for Identifying Students in Need of Assistance",
        "author": [
            "Karo Castro-Wunsch",
            "Alireza Ahadi",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03Castro-WunschA17"
    },
    {
        "comment": "<b>Best Paper Award</b>",
        "keywords": "CS1, assessments, concepts, exams, novice programming, questions, syntax",
        "acmid": "3013500",
        "doi": "10.1145/3013499.3013500",
        "url": "http://doi.acm.org/10.1145/3013499.3013500",
        "numpages": "10",
        "pages": "26--35",
        "location": "Geelong, VIC, Australia",
        "isbn": "978-1-4503-4823-2",
        "year": "2017",
        "series": "ACE '17",
        "booktitle": "Proceedings of the Nineteenth Australasian Computing Education Conference",
        "title": "The Compound Nature of Novice Programming Assessments",
        "author": [
            "Andrew Luxton-Reilly",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "02Luxton-ReillyP17"
    },
    {
        "keywords": "academic integrity, collusion, plagiarism, programming education",
        "acmid": "3024910",
        "doi": "10.1145/3024906.3024910",
        "url": "http://doi.acm.org/10.1145/3024906.3024910",
        "numpages": "24",
        "pages": "57--80",
        "location": "Arequipa, Peru",
        "isbn": "978-1-4503-4882-9",
        "year": "2016",
        "series": "ITiCSE '16",
        "booktitle": "Proceedings of the 2016 {ITiCSE} Working Group Reports",
        "title": "Negotiating the Maze of Academic Integrity in Computing Education",
        "author": [
            "Simon",
            "Judy Sheard",
            "Michael Morgan",
            "Andrew Petersen",
            "Amber Settle",
            "Jane Sinclair",
            "Gerry Cross",
            "Charles Riedesel"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "06SimonS16"
    },
    {
        "keywords": "computing education research, publication bias, replication, reproduction, research process, validation, verification",
        "acmid": "2999554",
        "doi": "10.1145/2999541.2999554",
        "url": "http://doi.acm.org/10.1145/2999541.2999554",
        "numpages": "10",
        "pages": "2--11",
        "location": "Koli, Finland",
        "isbn": "978-1-4503-4770-9",
        "year": "2016",
        "series": "Koli Calling '16",
        "booktitle": "Proceedings of the 16th Koli Calling International Conference on Computing Education Research",
        "title": "Replication in Computing Education Research: Researcher Attitudes and Experiences",
        "author": [
            "Alireza Ahadi",
            "Arto Hellas",
            "Petri Ihantola",
            "Ari Korhonen",
            "Andrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11AhadiH16"
    },
    {
        "comment": "<b>Honorary Mention: Runner-up for best paper</b>",
        "keywords": "CS1, dropping, retention",
        "acmid": "2999552",
        "doi": "10.1145/2999541.2999552",
        "url": "http://doi.acm.org/10.1145/2999541.2999552",
        "numpages": "10",
        "pages": "71--80",
        "location": "Koli, Finland",
        "isbn": "978-1-4503-4770-9",
        "year": "2016",
        "series": "Koli Calling '16",
        "booktitle": "Proceedings of the 16th Koli Calling International Conference on Computing Education Research",
        "title": "Revisiting Why Students Drop CS1",
        "author": [
            "Andrew Petersen",
            "Michelle Craig",
            "Jennifer Campbell",
            "Anya Tafliovich"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11PetersenC16"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/icer/HovemeyerHPS16",
        "timestamp": "Fri, 19 Aug 2016 09:39:36 +0200",
        "doi": "10.1145/2960310.2960326",
        "url": "http://doi.acm.org/10.1145/2960310.2960326",
        "year": "2016",
        "pages": "63--72",
        "booktitle": "Proceedings of the 2016 {ACM} Conference on International Computing\nEducation Research, {ICER} 2016, Melbourne, VIC, Australia, September\n8-12, 2016",
        "title": "Control-Flow-Only Abstract Syntax Trees for Analyzing Students' Programming\nProgress",
        "author": [
            "David Hovemeyer and\nArto Hellas and\nAndrew Petersen and\nJaime Spacco"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "08DBLP:conf/icer/HovemeyerHPS16"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/iticse/PetersenCD16",
        "timestamp": "Sun, 10 Jul 2016 19:07:31 +0200",
        "doi": "10.1145/2899415.2925503",
        "url": "http://doi.acm.org/10.1145/2899415.2925503",
        "year": "2016",
        "pages": "252--253",
        "booktitle": "Proceedings of the 2016 {ACM} Conference on Innovation and Technology\nin Computer Science Education",
        "title": "Employing Multiple-Answer Multiple Choice Questions",
        "author": [
            "Andrew Petersen and\nMichelle Craig and\nPaul Denny"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07DBLP:conf/iticse/PetersenCD16"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/iticse/IhantolaVABBEIK15",
        "timestamp": "Thu, 18 Aug 2016 01:00:00 +0200",
        "doi": "10.1145/2858796.2858798",
        "url": "http://doi.acm.org/10.1145/2858796.2858798",
        "year": "2015",
        "pages": "41--63",
        "booktitle": "Proceedings of the 2015 ITiCSE Working Group Reports, {ITICSE-WGR}\n2015, Vilnius, Lithuania, July 4-8, 2015",
        "title": "Educational Data Mining and Learning Analytics in Programming: Literature\nReview and Case Studies",
        "author": [
            "Petri Ihantola and\nArto Vihavainen and\nAlireza Ahadi and\nMatthew Butler and\nJ{\\\"{u}}rgen B{\\\"{o}}rstler and\nStephen H. Edwards and\nEssi Isohanni and\nAri Korhonen and\nAndrew Petersen and\nKelly Rivers and\nMiguel {\\'{A}}ngel Rubio and\nJudy Sheard and\nBronius Skupas and\nJaime Spacco and\nClaudia Szabo and\nDaniel Toll"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07DBLP:conf/iticse/IhantolaVABBEIK15"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/iticse/ParreiraPC15",
        "timestamp": "Sat, 27 Jun 2015 15:44:10 +0200",
        "doi": "10.1145/2729094.2754852",
        "url": "http://doi.acm.org/10.1145/2729094.2754852",
        "year": "2015",
        "pages": "347",
        "booktitle": "Proceedings of the 2015 {ACM} Conference on Innovation and Technology\nin Computer Science Education",
        "title": "{PCRS-C:} Helping Students Learn {C}",
        "author": [
            "Daniel Marchena Parreira and\nAndrew Petersen and\nMichelle Craig"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "07DBLP:conf/iticse/ParreiraPC15"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/kolicalling/PetersenSV15",
        "timestamp": "Mon, 23 Nov 2015 19:16:05 +0100",
        "doi": "10.1145/2828959.2828966",
        "url": "http://doi.acm.org/10.1145/2828959.2828966",
        "year": "2015",
        "pages": "77--86",
        "booktitle": "Proceedings of the 15th Koli Calling Conference on Computing Education\nResearch, Koli, Finland, November 19-22, 2015",
        "title": "An exploration of error quotient in multiple contexts",
        "author": [
            "Andrew Petersen and\nJaime Spacco and\nArto Vihavainen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11DBLP:conf/kolicalling/PetersenSV15"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/kolicalling/SmithZP15",
        "timestamp": "Mon, 23 Nov 2015 19:16:05 +0100",
        "doi": "10.1145/2828959.2828980",
        "url": "http://doi.acm.org/10.1145/2828959.2828980",
        "year": "2015",
        "pages": "171--172",
        "booktitle": "Proceedings of the 15th Koli Calling Conference on Computing Education\nResearch, Koli, Finland, November 19-22, 2015",
        "title": "Modern goto: novice programmer usage of non-standard control flow",
        "author": [
            "Stewart D. Smith and\nNicholas Zemljic and\nAndrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "11DBLP:conf/kolicalling/SmithZP15"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/sigcse/CherenkovaZP14",
        "timestamp": "Mon, 24 Feb 2014 13:38:26 +0100",
        "doi": "10.1145/2538862.2538966",
        "url": "http://doi.acm.org/10.1145/2538862.2538966",
        "year": "2014",
        "pages": "695--700",
        "booktitle": "The 45th {ACM} Technical Symposium on Computer Science Education,\n{SIGCSE} '14, Atlanta, GA, {USA} - March 05 - 08, 2014",
        "title": "Identifying challenging {CS1} concepts in a large problem dataset",
        "author": [
            "Yuliya Cherenkova and\nDaniel Zingaro and\nAndrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03DBLP:conf/sigcse/CherenkovaZP14"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/sigcse/ZingaroCKP13",
        "timestamp": "Sat, 09 Mar 2013 14:11:35 +0100",
        "doi": "10.1145/2445196.2445369",
        "url": "http://doi.acm.org/10.1145/2445196.2445369",
        "year": "2013",
        "pages": "585--590",
        "booktitle": "The 44th {ACM} Technical Symposium on Computer Science Education,\n{SIGCSE} '13, Denver, CO, USA, March 6-9, 2013",
        "title": "Facilitating code-writing in {PI} classes",
        "author": [
            "Daniel Zingaro and\nYuliya Cherenkova and\nOlessia Karpova and\nAndrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03DBLP:conf/sigcse/ZingaroCKP13"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/sigcse/ZingaroPC12",
        "timestamp": "Mon, 05 Mar 2012 08:17:41 +0100",
        "doi": "10.1145/2157136.2157215",
        "url": "http://doi.acm.org/10.1145/2157136.2157215",
        "year": "2012",
        "pages": "253--258",
        "booktitle": "Proceedings of the 43rd {ACM} technical symposium on Computer science\neducation, {SIGCSE} 2012, Raleigh, NC, USA, February 29 - March 3,\n2012",
        "title": "Stepping up to integrative questions on {CS1} exams",
        "author": [
            "Daniel Zingaro and\nAndrew Petersen and\nMichelle Craig"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03DBLP:conf/sigcse/ZingaroPC12"
    },
    {
        "comment": "<b>National Best Zone Paper</b>",
        "year": "2011",
        "booktitle": "American Society for Engineering Education (ASEE) Annual Conference Proceedings",
        "title": "Implementing Social Learning Strategies: Team Testing",
        "author": [
            "Rebecca Bates and\nAndrew Petersen"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "BatesP11"
    },
    {
        "bibsource": "dblp computer science bibliography, http://dblp.org",
        "biburl": "http://dblp.uni-trier.de/rec/bib/conf/sigcse/PetersenCZ11",
        "timestamp": "Mon, 05 Mar 2012 08:55:53 +0100",
        "doi": "10.1145/1953163.1953340",
        "url": "http://doi.acm.org/10.1145/1953163.1953340",
        "year": "2011",
        "pages": "631--636",
        "booktitle": "Proceedings of the 42nd {ACM} technical symposium on Computer science\neducation, {SIGCSE} 2011, Dallas, TX, USA, March 9-12, 2011",
        "title": "Reviewing {CS1} exam question content",
        "author": [
            "Andrew Petersen and\nMichelle Craig and\nDaniel Zingaro"
        ],
        "ENTRYTYPE": "inproceedings",
        "ID": "03DBLP:conf/sigcse/PetersenCZ11"
    },
    {
        "year": "2010",
        "month": "April",
        "issue": "2",
        "volume": "3",
        "pages": "8",
        "booktitle": "Ubiquitous Learning",
        "title": "Learning Outcomes Assessment Matrix ({LOAM}): a Software-Supported Process for Identifying and Scaffolding Complex Learning Outcomes",
        "author": [
            "Joanna Szurmak and\nAndrew Petersen"
        ],
        "ENTRYTYPE": "article",
        "ID": "04SzurmarkP10"
    }
]